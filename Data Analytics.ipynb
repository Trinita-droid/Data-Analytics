{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64b70a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"hey\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4969886b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "array_1=np.array([1,2,3])\n",
    "print(array_1)\n",
    "print(type(array_1))\n",
    "print(array_1.shape)\n",
    "array_1\n",
    "array_2= np.array([[4,5],[7,8]])\n",
    "array_2\n",
    "print(\"new array = \", array_2[1][1])\n",
    "array_2.shape\n",
    "array_2[0][1] = 31\n",
    "print(array_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e34b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "arrR = np.linspace(0,10,20)\n",
    "arrR\n",
    "# linspace generates evenly spaced out values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c26fe5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(0,20,2)\n",
    "# same as range function (start,stop,step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66dc8d43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ran=np.random.rand(10,3)\n",
    "print(ran)\n",
    "np.diag(ran)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda3ef8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(np.ones((2,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72de4c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.twos((4,5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca04d3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "s=5\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22343f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "v=np.array([2,3,4,5,])\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a81717d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = np.array([[3,4,6],[7,8,9]])\n",
    "print(n)\n",
    "type(n)\n",
    "print(n.shape)\n",
    "n.reshape(3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b612320",
   "metadata": {},
   "outputs": [],
   "source": [
    "r1=np.random.rand(3,3)\n",
    "r1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f13268",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "r2=np.random.rand(3,3)\n",
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ba41e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "r3=np.array([r1,r2])\n",
    "r3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7dc5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "a1=np.random.rand(3,3)\n",
    "a2=np.random.rand(3,3)\n",
    "print(\"Sum is \", a1+a2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b881814",
   "metadata": {},
   "outputs": [],
   "source": [
    "(a1+a2).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5c56d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "c=np.random.rand(3,2)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec24cb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import relevant library\n",
    "import numpy as np\n",
    "c=np.random.rand(3,2)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ca20d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "c.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c384853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transposing scalar\n",
    "d=np.random.rand(5)\n",
    "d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b373ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "d.t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23311285",
   "metadata": {},
   "outputs": [],
   "source": [
    "d.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b05f834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transposing scalar\n",
    "d=np.random.rand(5)\n",
    "print(d)\n",
    "print(d.T)\n",
    "# in python 1-dimensional arrays dont get transposed , but can be done when reshaped though\n",
    "reshaped=d.reshape(1,5)\n",
    "reshaped.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7d7bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transposing vector\n",
    "v=np.random.rand(2,3)\n",
    "print(v)\n",
    "print(v.T)\n",
    "print(v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0ed5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dot product\n",
    "add_1=np.array([2,4,5])\n",
    "add_2=np.array([7,8,9])\n",
    "sum=np.dot(add_1,add_2)\n",
    "sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d40054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scalar * scalar\n",
    "np.dot(19,45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0054cecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scalar*vector = vector with same length\n",
    "add_1 * 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f203a4bb",
   "metadata": {},
   "source": [
    "# scalar * matrix\n",
    "e=np.random.rand(3,4)\n",
    "sum * e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdde3ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c = (2,3,4)\n",
    "print(b,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c944374",
   "metadata": {},
   "outputs": [],
   "source": [
    "x='J'\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ace5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fi(i):\n",
    "    x=5\n",
    "    return x\n",
    "fi(9)\n",
    "# print(fi())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef35700",
   "metadata": {},
   "outputs": [],
   "source": [
    "True and not False or True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8b08d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# func in a func\n",
    "def wage(work_hours):\n",
    "    return work_hours * 30\n",
    "print(\"Total wages is : Rs\",wage(9))\n",
    "def bonus(work_hours):\n",
    "    return wage(work_hours) + 100\n",
    "# wage(9)\n",
    "print(\"Bonus received is : Rs\", bonus(9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c1120a",
   "metadata": {},
   "outputs": [],
   "source": [
    "max(0,5,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648ba9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "min(9,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1bf02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "list=[5,6,7]\n",
    "list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9933377b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f689cbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "round(0.99999,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f23d72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "round(3.5678,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8864b63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "round(3.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e420b1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pow(9,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e57a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "len('trinita ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601ebb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lists\n",
    "\n",
    "part=['rhea','leah','jez','trini']\n",
    "part.sort()\n",
    "print(part)\n",
    "\n",
    "print(part[-1])\n",
    "del part[0]\n",
    "print(part)\n",
    "part[0]='rheah'\n",
    "print(part)\n",
    "part.append('maria')\n",
    "print(part)\n",
    "part.extend([\"jo\", \"ann\"])\n",
    "print(part)\n",
    "print('The first on list is ' +part[0]+ '.')\n",
    "len(part)\n",
    "# slicing\n",
    "\n",
    "part[-1:-3:-1]\n",
    "part.index('jo')\n",
    "list_2=[\"soph\",\"aire\"]\n",
    "part1=[part,list_2]\n",
    "print(part1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905f825e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=['e','r','a']\n",
    "n=['t','f']\n",
    "b=[a,n]\n",
    "print (b)\n",
    "a.sort()\n",
    "print(a)\n",
    "a.sort(reverse=True)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97735f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuples - cannot be modified\n",
    "x=(5,6,7,1)\n",
    "y=(0,6)\n",
    "print(x[3])\n",
    "x,e,r=5,8,9\n",
    "e,r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19438b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# placing tuples within list\n",
    "x=(5,6,7,1)\n",
    "y=(0,6)\n",
    "list=[(x,y)]\n",
    "list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0a0cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "age,year=\"23,2000\".split(',')\n",
    "age,year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30ca51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions can return tuples as return values\n",
    "def tup_val(x):\n",
    "    A=x**2\n",
    "    P=4*x\n",
    "    print(\"Area and Perimeter is as follows : \")\n",
    "    return (A,P)\n",
    "tup_val(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94f385f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dicionaries\n",
    "dict={'name':'trini','age':23,'single':'yes'}\n",
    "print(dict['name'])\n",
    "dict['profession']='software Engg'\n",
    "print(dict)\n",
    "dict1={'countries':' Hawaii,Utah,Alaska '}\n",
    "dict1['countries']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff28503",
   "metadata": {},
   "outputs": [],
   "source": [
    "deps={'dep1':['q,r'],'dep2':'o'}\n",
    "# deps['dep1']\n",
    "deps.get('dep2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02c321a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# while loop\n",
    "x=1\n",
    "while x<=7:\n",
    "    print(x,end=\" \")\n",
    "    x+=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ea2008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# range(start,stop,step)\n",
    "print(list(range(3,8,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcf6533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to count the number of items in a list with values less than 20\n",
    "list_1=[23,5,7,8,9,12,15,67,78,90,18,2,11]\n",
    "print(\"Here is our list : \",list_1)\n",
    "len_list_1=len(list_1)\n",
    "print(\"Length of our list is : \",len_list_1)\n",
    "def count(numbers):\n",
    "    c=0\n",
    "    for i in numbers:\n",
    "        if i<20:\n",
    "            c=c+1\n",
    "    return c\n",
    "number_l=[2,3,32,12,13,14,15,65,76,0,69]\n",
    "count(number_l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb23623c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nums = [1,35,12,24,31,51,70,100]\n",
    "i=0\n",
    "nums[i]\n",
    "i=i+1\n",
    "print(nums[i])\n",
    "\n",
    "\n",
    "# for item in nums:\n",
    "#     while nums[0]<20:\n",
    "#         c=0 \n",
    "#         c=c+1\n",
    "#         print (c)\n",
    "#         nums[0]++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd764d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "nums = [10, 35, 12, 24, 31, 51, 70, 100]\n",
    "def c_l(nums):\n",
    "    count = 0\n",
    "    i = 0\n",
    "\n",
    "    while i < len(nums):\n",
    "        if nums[i]<20:\n",
    "            count += 1\n",
    "        i += 1\n",
    "    return count\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aebd832",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90d8805",
   "metadata": {},
   "outputs": [],
   "source": [
    "nums = [1,35,12,24,31,51,70,100]\n",
    " \n",
    "def count(nums):\n",
    "    count = 0\n",
    "    b = 0\n",
    " \n",
    "    while b < len(nums):\n",
    "        if nums[b] < 20:\n",
    "            count += 1\n",
    "        b += 1  # Don't forget to increment b to avoid an infinite loop\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e322b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iteration through dict\n",
    "prices={\"lasagna\":4,\"burgers\":5}\n",
    "quantity={\"lasagna_q\":1,\"burgers_q\":2}\n",
    "# prices,quantity\n",
    "for key in prices.keys() & quantity.keys():\n",
    "    amt=0\n",
    "    amt=amt+(prices[key]*quantity[key])\n",
    "    print(amt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e1e8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas is a python library and it is built on numpy -- panel (multiple observations over diff periods of time) + data\n",
    "'''\n",
    "pandas focus more on analytic tasks while numpy , computational tasks\n",
    "2 important data structures of pandas : series(single column data \n",
    "), dataframe objects(multi column data)'''\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# to check version\n",
    "np.__version__\n",
    "pd.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7f983a",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_1=[3,4,5]\n",
    "list_2=[3,1,1]\n",
    "print(list_1.extend(list_2))\n",
    "# l_3=(list_1,list_2)\n",
    "l_3=list_1.extend(list_2)\n",
    "print(l_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265ac852",
   "metadata": {},
   "outputs": [],
   "source": [
    "        import numpy as np\n",
    "        time_0 = np.arange(0, 10000, 0.1)\n",
    "        time_1 = np.arange(0, 11000, 0.1)\n",
    "        time_0 = np.delete(time_0, np.argwhere((time_0 > 100) & (time_0 < 120)), axis=0)\n",
    "        time_1 = np.delete(time_1, np.argwhere((time_1 > 80) & (time_1 < 120)), axis=0)\n",
    "        ti_dict = {\"_time_0\": time_0, \"_time_1\": time_1}\n",
    "        ti_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce776b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# why numpy and pandas?\n",
    "\"\"\"ND class of numpy array works well on computing values because operations work element wise\n",
    "pandas works with array structure. pandas has series(vector - single column data, corrsponds to 1d array in numpy) and df(matrix, corresponds to 2d array structure in numpy) objects.\n",
    "NUMPY for numerical operations and PANDAS for dataset analysis;store data in series/df\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135f0f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8077709b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5cb430",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e21340",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3496977a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b270dd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d5aa17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a series is a single column data and hence series object can be created from a list.\n",
    "products = ['A','B','C','D']\n",
    "print(products)\n",
    "print(type(products))\n",
    "products_series = pd.Series(products)\n",
    "products_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63334344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating series datastructure by placing the list inside.\n",
    "dollar_rates = pd.Series([23,67,89])\n",
    "dollar_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da895d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "array_a = np.array([1,4,9,0])\n",
    "print(array_a)\n",
    "type(array_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208e7438",
   "metadata": {},
   "outputs": [],
   "source": [
    "array_to_pandas = pd.Series(array_a)\n",
    "array_to_pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5754e28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "array_to_pandas = pd.Series(array_a)\n",
    "print(array_to_pandas)\n",
    "pandas_to_array1 = pd.Series(array_a)\n",
    "pandas_to_array = np.array(pandas_to_array1)\n",
    "pandas_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941d1bdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44032e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#attribute - variable providing metadata about an object, attributes extract info about certain python related objects.\n",
    "#method - function assosciated with object. python objects is collection of methods and attributes.\n",
    "# len and size gives the number of elements in the underlying data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00871ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "ser_a=pd.Series([1,2,3])\n",
    "print(ser_a,type(ser_a),ser_a.size,len(ser_a))\n",
    "pan_a=pd.DataFrame([1,2,3])\n",
    "print(pan_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3698930c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ser_a.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d3e9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to assign a name to a pandas series object\n",
    "ser_a.name = 'SeriesA'\n",
    "ser_a.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e06e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "work_experience_years = pd.Series([5,8,3,10])\n",
    "print(work_experience_years)\n",
    "work_experience_years = np.array(work_experience_years)\n",
    "print(work_experience_years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdf27d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "work_experience_years = pd.Series([5,8,3,10])\n",
    "# print(type(work_experience_years.to_numpy()))\n",
    "print(work_experience_years.to_numpy())\n",
    "print(type(work_experience_years.to_numpy()))\n",
    "work_experience_years.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00693870",
   "metadata": {},
   "outputs": [],
   "source": [
    "work_experience_years = pd.Series([5,8,3,10])\n",
    "work_experience_years.name='AD'\n",
    "print(work_experience_years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799092e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dict - dict to series is done to preserve the data values. can access the labels through keys. dict is a way to access indexing. index values give access to data points.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "dict_a = {'Trini':23,'Hari':25,'Pauline':24}\n",
    "print(type(dict_a))\n",
    "dict_aS=pd.Series(dict_a)\n",
    "print(type(dict_ab))\n",
    "# dict_aN=np.array(dict_a)\n",
    "# print(dict_aN)\n",
    "dict_aS.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ccc2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index data structures in pandas - refer to a position, index DS speeds up computation process.in pandas we have implicit indices -> label based and position based.\n",
    "# dictionary level of indexing is explicit indexing.. \n",
    "# label and position based indexing :\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "to_series = pd.Series([3,5,7,8])\n",
    "print(to_series)\n",
    "print(to_series.index)\n",
    "print(type(to_series.index))\n",
    "\n",
    "dict_a = {'Trini':23,'Hari':25,'Pauline':24}\n",
    "dict_series = pd.Series(dict_a)\n",
    "print(dict_series)\n",
    "print(type(dict_series.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ffbdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating 2 objects\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "ser_array = pd.Series([2,8,9,0]) #implicit zero based indexing\n",
    "dictionary = {'Trini':23,'Hari':25,'Pauline':24}\n",
    "dict_array = pd.Series(dictionary)\n",
    "print(ser_array)\n",
    "print(dict_array)\n",
    "# create explicit indexing\n",
    "imp_series = pd.Series([5,7,9,0],index = (2,22,3,4))\n",
    "print(imp_series)\n",
    "# integer 1 to 5 written as strings will be the index labels\n",
    "imp_series2 = pd.Series([5,7,9,0],index = [2,22,3,4])\n",
    "print(\"index referred as string : \", imp_series2[2])\n",
    "print(\"label : \", imp_series2[2])\n",
    "\n",
    "# if we refer to index value as 1 as string, it prints the value associated with the key 1 in the index provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f991cd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dictionary['Trini'])\n",
    "print(dictionary.items())\n",
    "print(dictionary.items)\n",
    "print(dictionary.keys)\n",
    "print(dictionary.keys())\n",
    "np_w = pd.Series(np.array([2,3,5,6]))\n",
    "print( np_w)\n",
    "np_wo= pd.Series([2,3,5,6])\n",
    "print(\"np_wo \", np_wo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366d1352",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# exercise on indexing:\n",
    "import pandas as pd\n",
    "\n",
    "employees_work_exp = pd.Series({'Martin':8, 'George':5})\n",
    "a=employees_work_exp.index[0]\n",
    "b = employees_work_exp['Martin']\n",
    "print((a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43337219",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "arr_1 = np.array([44,54,65,35])\n",
    "ser_age = pd.Series(arr_1)\n",
    "print(ser_age)\n",
    "\n",
    "series_age = pd.Series(np.array([44, 54, 65, 35]))\n",
    "print(series_age.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0478ec5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c775cc9f-9744-441f-ab1c-49557dd52947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attributes -> refer to metadata ; methods -> functionality of object. \n",
    "# function is an independent entity, method is applied to an object with certain class when called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116106c3-b092-4bd5-aef0-2f2e18386def",
   "metadata": {},
   "outputs": [],
   "source": [
    "# methods in pandas series  - max, min, sum, idmax, idmin(). Pandas is built on numpy.\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "start_deposits = pd.Series( {\n",
    "    '1/23' : 45,\n",
    "    '34/5' : 67,\n",
    "    '89/6' : 52,\n",
    "    '09/3' : 87,\n",
    "    '87' : 12,\n",
    "    '49' : 32,\n",
    "    '89' : 40\n",
    "    })\n",
    "print(start_deposits.min())\n",
    "\n",
    "# index label corresponding to highest value in a series - idmax() method.\n",
    "\n",
    "# head is used to obtain the first five rows and tail method last 5 rows, this way we can get a glipse of our datastructure.\n",
    "print(\"tail\")\n",
    "start_deposits.tail()\n",
    "\n",
    "# always required to add paranthesis after function in order for it provide a value.\n",
    "\n",
    "# why 2 different libraries numpy and pandas if they have identical numerical methods : \n",
    "# if we are sure our dataset contains only numerical data present, then numpy and its methods can be chosen. When working with numeric and non-numeric dataset, \n",
    "# pandas will set the ground.\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40e9530-8ed9-4ed8-a326-8e38f2e810f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "employees_work_exp = pd.Series({\n",
    "'Amy White'   : 3,\n",
    "'Jack Stewart'   : 5,\n",
    "'Richard Lauderdale'  : 4.5,\n",
    "'Sara Johnson'  : 22,\n",
    "'Patrick Adams' : 28,\n",
    "'Jessica Baker'  : 14,\n",
    "'Peter Hunt'   : 4,\n",
    "'Daniel Lloyd'  : 6,\n",
    "'John Owen'   : 1.5,\n",
    "'Jennifer Phillips'  : 10,\n",
    "'Courtney Rogers'   : 4.5,\n",
    "'Anne Robinson'  : 2,\n",
    "})\n",
    "print(\" employees_work_exp :\\n\", employees_work_exp)\n",
    "\n",
    "# following prints an empty line\n",
    "print()\n",
    "\n",
    "#  best feature of methods is that we can modify their performance. This can be acheived by knowing the parameters for method given and providing arguments. \n",
    "# we can supply parameters with arguments to modify the performance of method. Use a pandas method to retrieve the first 8 records of the object.\n",
    "print(\"extract first 8 rows :\\n \", employees_work_exp.head(n=8))\n",
    "print()\n",
    "# fetching total number of rows in a dataset\n",
    "print(\"rows :\",employees_work_exp.shape[0])\n",
    "# print(\"cols :\",employees_work_exp.shape[1])\n",
    "\n",
    "# -----DataFramea have to be created like this----------\n",
    "\n",
    "employees_work_exp_df = pd.DataFrame({\n",
    "    'Employee': ['Amy White', 'Jack Stewart', 'Richard Lauderdale', 'Sara Johnson', 'Patrick Adams', \n",
    "                 'Jessica Baker', 'Peter Hunt', 'Daniel Lloyd', 'John Owen', 'Jennifer Phillips', \n",
    "                 'Courtney Rogers', 'Anne Robinson'],\n",
    "    'Work_Experience': [3, 5, 4.5, 22, 28, 14, 4, 6, 1.5, 10, 4.5, 2],\n",
    "})\n",
    "\n",
    "# this method will display the rows\n",
    "r= employees_work_exp_df.index\n",
    "print(\"r \", r)\n",
    "\n",
    "# this method will display the cols\n",
    "print(\"cols \",employees_work_exp_df.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ac0347-2b9f-4283-8f67-b70344986e5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5d493f-61cf-48f7-9a75-813919c80cac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "149743c7-fb2c-4a48-844f-29a3b98a795f",
   "metadata": {},
   "source": [
    "# SHIFT + TAB TAB TAB -> for further info on method from the documentation.\n",
    "# Series is a single column data or set if values that correspond to single variable. info containing single data type.\n",
    "# DataFrame is a multi column data : every column represents diff variable, heterogenous - meaning containing not same data type. -> actually is a set of multiple series.\n",
    "# must aim to keep data of single type for data consistency within a certain column.\n",
    "# Series - 1D(single axis), DataFrame - 2D(x and y axis).\n",
    "# all methods that are applied to series can also be implemented for each column in dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ac93b5-05d5-459b-abc9-91b4564db52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Series is a powerful version of python list, and also contains some dictionary features.DataFrame is an enhanced python dictionary. creating series and dataframe\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "series_a = [2,4,56,78,0,6,4,6,8,9] #creating list\n",
    "print(\"before series list : \", series_a)\n",
    "py_ser_a = pd.Series(series_a) #creating series object\n",
    "print(\"after converting to series object : \\n\",py_ser_a)\n",
    "py_df_a = pd.DataFrame(series_a) \n",
    "print(\"after converting to df object : \\n\",py_df_a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35144645-a890-45d0-8dba-0f4539544014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DF EXAMPLE 2 - construct a dataframe with dictionary with lists\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "data = {\"Names\" : [\"T,P,H\"] , \"P\" : [\"S,H,T\"] }\n",
    "# print(\"before conv : \\n\", data)\n",
    "# ser_data = pd.Series(data)\n",
    "# print(\"series data : \\n\", ser_data)\n",
    "df_data = pd.DataFrame(data)\n",
    "print(\"df data : \\n\", df_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1316a196-3a2e-4602-9527-d1ce21852ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DF EXAMPLE 3 - construct a dataframe with dictionary of lists\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "data = {\n",
    "    'Name':['Amy White', 'Jack Stewart', 'Richard Lauderdale', 'Sara Johnson'],\n",
    "    'Age':[50,53,35,43],\n",
    "    'Working Experience (Yrs.)':[5,8,3,10]\n",
    "}\n",
    "df = pd.DataFrame (\n",
    "    data\n",
    "    )\n",
    "print(\"df : \\n\",df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4022f851-0880-426f-bc70-073b55d9a761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DF EXAMPLE 4 - construct a dataframe that contains dictionaries as elements\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "data = [\n",
    "    {'Name':['Amy White', 'Jack Stewart', 'Richard Lauderdale', 'Sara Johnson']},\n",
    "    {'Age':[50,53,35,43]},\n",
    "    {'Working Experience (Yrs.)':[5,8,3,10]}\n",
    "]\n",
    "df = pd.DataFrame (\n",
    "    data\n",
    "    )\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976442fb-83a9-431a-8d09-e397e5c88c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DF EXAMPLE 5 - construct a dataframe from pandas series\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "ser_name =pd.Series(['Trini','Pauline','Hari'],index =['A','b','c'])\n",
    "ser_age=pd.Series([23,24,25], index =['b','c','A'])\n",
    "df_from_series = {'Names': ser_name, 'Ages':ser_age}\n",
    "result=pd.DataFrame(df_from_series)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ff4742-c26b-4db9-98fd-41911e646378",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  DF EXAMPLE 6 - construct a dataframe from lists of lists\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "ser_name =['Name','Trini'],['Age',23,24],['R','C']\n",
    "result=pd.DataFrame(ser_name)\n",
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225e27a9-3553-4d84-8121-03ed97ac80b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  DF EXAMPLE 6 - construct a dataframe in a professional way\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "prof_df = pd.DataFrame(\n",
    "    data =[['Trini',23],['Judes',23]],\n",
    "    columns =[\"names\",\"ages\"],\n",
    "    index = [4,5]  \n",
    ")\n",
    "print(prof_df)\n",
    "prof_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c69953e-547d-4d2e-a992-c5a8caf297c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "names = pd.Series(['Amy White', 'Jack Stewart', 'Richard Lauderdale', 'Sara Johnson'])\n",
    "age=pd.Series([50,53,35,43])\n",
    "working_experience_yrs=pd.Series([5,8,3,10])\n",
    "data = {\n",
    "    'Name':names,'Age':age,'Working Experience (Yrs.)': working_experience_yrs\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cac883-4094-4221-9d19-6f7d4149a5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "data1 = [['Name'],['Amy White', 'Jack Stewart', 'Richard Lauderdale', 'Sara Johnson'],['Age'],[50,53,35,43],['Working'],[5,8,3,10]]\n",
    "df=pd.DataFrame(data1,index=['q','w','e','r','p','p'])\n",
    "print(df)\n",
    "data = {\n",
    "    \"Name\":['Amy White', 'Jack Stewart', 'Richard Lauderdale', 'Sara Johnson'], \n",
    "    \"Age\":[50, 53, 35, 43], \n",
    "    \"Working Experience (Yrs.)\":[5,8,3,10]}\n",
    "df = pd.DataFrame(data,index = [1,2,3,4])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d730fc4-06ca-46f3-b675-b63e1943723b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"Name\":['Amy White', 'Jack Stewart', 'Richard Lauderdale', 'Sara Johnson'], \n",
    "    \"Age\":[50, 53, 35, 43], \n",
    "    \"Working Experience (Yrs.)\":[5,8,3,10]}\n",
    "df = pd.DataFrame(data,index = [1,2,3,4])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c544bdc2-4778-44b8-8d5d-ea667bbfd377",
   "metadata": {},
   "source": [
    "Python maintains/can handle 2 types of files : text file and binary files.\n",
    "\n",
    "Text files - each line contains characters, symbols - electronic texts\n",
    "Text files are indispensable today due to ease and fast transfer of data to and from the server.\n",
    "Text files dont contain metadata, meaning they dont have any information stored in them regarding the data.\n",
    "ASCII - American Standard Code for Information Interchange.\n",
    "\n",
    "Binary file - written in binary language/machine language containing 1s and 0s.\n",
    "Due to its file type, its content can only be processed and accessed by an application that knows and understands its structure.\n",
    "Contrary to text files, binary files do not contain line terminators.\n",
    "\n",
    "Text file and text data are 2 different terms.\n",
    "Text file - certain type of file.\n",
    "Text data - contains texts.\n",
    "numeric data - contains numbers\n",
    "bool data - true/false.\n",
    "\n",
    "----------\n",
    "File VS File object : \n",
    "\n",
    "File - item that can be created, modified and stored by the user or operating system. Is of the form text file or binary file.\n",
    "File Object - refers to the data imported from the file. To work with files that are stored in the computer we have to import them and convert them into file object. => Hence we will import text files into python as file object and manipulate these objects by cleaning,preprocessing and analysing data\n",
    "\n",
    "-----------\n",
    "Reading VS parsing a text file :\n",
    "Reading - goal of reading a file is to simply transfer its text into computer's memory. when working in python this will be the working memory/RAM.\n",
    "Once the process of reading a file is complete, it will be stored as object.\n",
    "Parsing or syntactic analysis is trying to understand the purpose of this python object.\n",
    "\n",
    "Classic analogy(example) of these 2 terms in real life would be the following. \n",
    "- copying an image in a machine is reading and a user trying to read and understand and name its segment would be parsing.\n",
    "- importing or loading a text file into python datastructure like series or dataframe is reading.\n",
    "- then specifying how this transfer is done for eg, by giving the index of the structure is parsing.\n",
    "\n",
    "----------\n",
    "Types of data according to organisation :\n",
    "1. Structured data - traditoinal data (stored in the form of databases, tabular form). Egs - excel spreadsheet, SQL database, pandas dataframe.\n",
    "2. Semi-structured data - uses different pattern for storing and organising data in a way that makes it easier to access\n",
    "3. Unstructured data - contains formats like video, audio, images,\n",
    "\n",
    "better structure -> easier navigation\n",
    "\n",
    "BIG DATA - refers to extremely large dataset that is allocated on multiple computers. \n",
    "Encoding - process of converting or translating text information into bytes.\n",
    "UTF-8 : 8 bit Unicode transformation format - encoding that turns the text to machine language (1s and 0s)\n",
    "\n",
    "--------\n",
    "upper camel case - UpperCamelCase (best practice for class names)\n",
    "lower camel case - lowerCamelCase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27862fe-182b-456a-86c4-5c563525873f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"source.txt\"\n",
    "file = open(filename,mode=\"r\")\n",
    "text=file.read() #displays content of file object\n",
    "print(text)\n",
    "# closing a file \n",
    "file.close()\n",
    "file.closed # to check status of file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e0f70f-fc81-4744-adaa-d0760f80cde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining the file with the with statement, we can also work with the data and the file closes automatically\n",
    "with open(\"source.txt\", \"r\") as output_file:\n",
    "    output_file.read()\n",
    "print(output_file)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f85f5cb-d8d9-44e0-b3e6-d9ddf430466f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"source.txt\",mode=\"w\") as write_file:\n",
    "    new_file=write_file.write(\"she's great\")\n",
    "new_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0730575-0754-4784-9474-9884e2e1e432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lending excel\n",
    "file2loc = \"C:/Users/TJO1COB/Downloads/Lending-company.csv\"\n",
    "file=open(file2loc,mode=\"r\")\n",
    "file_r=file.read()\n",
    "print(file_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1778baf2-46e2-4850-89dc-1f27ef82e8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(file_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7be2f7-c363-479e-81a2-3ca95660be98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# organising the above dataset as a table using the pandas read_csv() method. read_csv() can read the txt files as well\n",
    "import pandas as pd\n",
    "pd.read_csv(\"C:/Users/TJO1COB/Downloads/Lending-company.csv\") #creates a df same as creating a dataframe\n",
    "# header refers to the first column name\n",
    "# .read_csv method is same as creating a dataframe constructor to convert into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfef63c-d72b-4766-b7c5-17bef8a7f93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "type(pd.read_csv(file2loc))\n",
    "# setting index columns\n",
    "# lend1_csv = pd.read_csv(file2loc,index_col=2,skipfooter=2)\n",
    "# print(lend1_csv)\n",
    "lend_csv = pd.read_csv(file2loc, header= 4)\n",
    "lend_csv\n",
    "\n",
    "# lend_csv1 = pd.read_csv(file2loc,index_col= \"Product\",usecols=[1])\n",
    "# lend_csv1\n",
    "# usecols - displays columns of interest\n",
    "# index -> columns ; index_col -> taking a col name from CSV and assigning to the first col."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5989e2ed-9f01-416d-8550-d572714333a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting index\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "friend_list = { \"Names\" : ['Paul', 'Hari', 'Trini'], \"Ages\" : [24,23,25]    \n",
    "}\n",
    "ind = ['C','H','C']\n",
    "final = pd.DataFrame(friend_list,ind)\n",
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda70db3-64b2-41e3-a48e-68b83607863b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"importing text files into python can be done in many ways :\n",
    "    particularly loadtxt & genfromtxt are common when dealing with csv files\n",
    "    loadtxt - loading the values. by default np.loadtxt() assumes all values will be numeric hence it crashes when it encounters textual data,\n",
    "    this can be bypassed by specifying the dtype to strings when importing\n",
    "    genfromtxt - generate from text and handles missing data well\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "lending_file_loc = \"C:/Users/TJO1COB/Downloads/Lending-company.csv\"\n",
    "file_load = pd.read_csv(lending_file_loc)\n",
    "file_load\n",
    "\n",
    "# define delimeters - predefined symbols like , ; - take up way less space\n",
    "file_deli = np.genfromtxt(lending_file_loc, delimiter=',')\n",
    "file_deli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd481fcf-0b08-46b5-907e-e6bbcb17ca95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61affd2-48c9-4727-9bc8-adf76abe0787",
   "metadata": {},
   "outputs": [],
   "source": [
    "lend_nan = np.genfromtxt(\"C:\\\\Users\\\\TJO1COB\\\\Downloads\\\\Lending-Company-Numeric-Data-NAN.csv\",\n",
    "                      delimiter=';',\n",
    "                     dtype = str)\n",
    "lend_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bef8fc-bb82-4af2-9f7d-d73e21e4539d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# partial cleaning while importing.many parameters of genfromtxt method are used below :\n",
    "# skip_header can omit as many lines from the top of dataset and skip_footer , the last lines of dataset.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "lend_csv = \"C:/Users/TJO1COB/Downloads/Lending-Company-Numeric-Data-NAN.csv\"\n",
    "file_load = np.genfromtxt(lend_csv,delimiter=';',skip_footer=1)\n",
    "file_load = np.genfromtxt(lend_csv,delimiter=';',skip_header=1)\n",
    "# usecols tells python that we're interested only in the first column. its good technique to sort the data to a given metric\n",
    "file_load,u = np.genfromtxt(lend_csv,delimiter=';',skip_header=1,usecols=[3,2],unpack=True)\n",
    "print(\"file_load , u :\\n \",file_load,u)\n",
    "\n",
    "# python uses 0 indexing for usecols parameters. not for header or footer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615ce68f-56e2-4a42-843c-9755d520d3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "lending_file = np.loadtxt(\"C:\\\\Users\\\\TJO1COB\\\\Downloads\\\\Lending-company.csv\", dtype=str,delimiter=',')\n",
    "lending_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f62e19-a751-4b74-9f78-61c180a29f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_loc = \"C:\\\\Users\\\\TJO1COB\\\\Downloads\\\\Lending-Company-Total-Price.csv\"\n",
    "load_file = np.loadtxt(file_loc,dtype=str,delimiter=',')\n",
    "print(load_file)\n",
    "\"\"\"the number of columns changed from 1 to 4 at row 2; use `usecols` to select a subset and avoid this error -\n",
    "to solve this error add a delimiter. use delimiter regardless of both the import ways.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9740c2a-2069-407d-b25e-97e0aeb22a5f",
   "metadata": {},
   "source": [
    "JSON format relies on 3 different concept :\n",
    "1. human-readable\n",
    "2. suitable to work with non-relational db\n",
    "3. organised as plain text which enhances speed and transfer of data. \n",
    "this file format is great to store data in a structure which corresponds to python dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bbb0e1-b16f-46d0-8945-0ac336b40c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import JSON module and use the loads() method to parse the string as dictionary\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "# my_bff_list = { \"Names\" : ['Paul', 'Hari', 'Trini'], \"Ages\" : [24,23,25], \"Profession\" : ['Teacher' , 'Software Engg' , 'HR'] }\n",
    "# type(my_bff_list)\n",
    "\n",
    "my_bffs = '{\"name\": \"ph\", \"profession\": \"thr\"}'\n",
    "type(my_bffs)\n",
    "print(\"string : \\n\",my_bffs)\n",
    "str_to_dict = json.loads(my_bffs)\n",
    "print(\"to_dict_using_loads() : \\n\",str_to_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79b5025-03e4-4aaf-8baf-f490b3c0910f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to load data in tabular form, import pandas library and use read_json method\n",
    "lend_comp_loc = \"C:/Users/TJO1COB/Downloads/Lending-company.json\"\n",
    "pandas_method = pd.read_json(lend_comp_loc)\n",
    "pandas_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270cf114-d4f8-46ef-a101-c4244f53ce6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data from excel spreadsheet into python\n",
    "import pandas as pd\n",
    "xls_loc = \"C:\\\\Users\\\\TJO1COB\\\\Downloads\\\\Lending-company.xlsx\"\n",
    "read_xl = pd.read_excel(xls_loc)\n",
    "read_xl\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbe5918-3032-444f-a986-9f89814c045b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "print(openpyxl.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09dbff95-05d6-4c4c-858c-be953358cf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip show openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd6dca3-a50a-4dbb-a9c4-68daf5ea02f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# head() method gives a glimpse of first few data\n",
    "import pandas as pd\n",
    "file_loc_3 = \"C:\\\\Users\\\\TJO1COB\\\\Downloads\\\\Lending-company.csv\"\n",
    "display_only_header = pd.read_csv(file_loc_3,usecols=['Region','StringID','LoanID','Product'],skipfooter=4,index_col='Region',engine='python',delimiter=',')\n",
    "display_only_header.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60d230f-2790-4dfc-8da3-06ff77ab0fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing data with pandas squeeze method - to obtain a series object; this can be obtained to dataframes containing a single row or column squeezed to a series. otherwise the object is unchanged.\n",
    "# we can pass 1s as arguments of sqeeze method - to sqeeze for horizontal axis. we can pass 1s(for columns) and 0s(for rows) as argument to the sqeeze method to indicate that we would like to sqeeze our data along.\n",
    "file_loc_3 = \"C:\\\\Users\\\\TJO1COB\\\\Downloads\\\\Lending-company.csv\"\n",
    "data_from_csv = pd.read_csv(file_loc_3,usecols=['Product'])\n",
    "print(\"data from csv : \\n\", data_from_csv.head())\n",
    "sqz = data_from_csv.squeeze(\"columns\")\n",
    "sqz\n",
    "\n",
    "# file_loc_4 = \"C:\\\\Users\\\\TJO1COB\\\\Downloads\\\\Customer-Gender.csv\"\n",
    "# data_from_csv = pd.read_csv(file_loc_3,usecols=1)\n",
    "# data_from_csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3198f40b-05d8-4f65-b029-80f1ca260510",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(sqz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ed0f10-4815-4675-bc24-00d26c5c6ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sqeeze method in pandas.\n",
    "import pandas as pd\n",
    "customer_gender = \"C:\\\\Users\\\\TJO1COB\\\\Downloads\\\\Customer-Gender.csv\"\n",
    "read_csv = pd.read_csv(customer_gender)\n",
    "\n",
    "sqz_cols = read_csv.squeeze()\n",
    "print(read_csv.head())\n",
    "sqz_cols.head()\n",
    "print(type(sqz_cols))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34187148-f1d0-41f2-966d-433e4f163b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving data with pandas : exporting data from python object into text file \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fd0f82-43bf-41fe-980e-ac6b449abb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "file_loc_4 = \"C:\\\\Users\\\\TJO1COB\\\\Downloads\\\\Lending-company.csv\"\n",
    "read_4 = pd.read_csv(file_loc_4)\n",
    "read_4.head()\n",
    "\n",
    "#  to export the data into csv file, add the to_csv method and provide the file name with extension as string argument\n",
    "read_4.to_csv('export_into_csv.csv',index=False)\n",
    "# exporting to JSON\n",
    "read_4.to_json('export_into_JSON.json')\n",
    "# exporting into xls without index\n",
    "read_4.to_excel('export_into_xls.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b7d83d-dc20-4219-8e1e-e859e33f9210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving data with numpy - using function np.save(); file is stored in a file type '.npy'. 2 arguments this function requires are file-name and dataset variable_name specified in the same order\n",
    "# an .npy file is 20x faster than regular CSV file loading in the sense that it is much faster in loading millions of data compared to the latter, takes up way less speed than CSV\n",
    "import numpy as np\n",
    "# importing data\n",
    "lend_co = \"C:\\\\Users\\\\TJO1COB\\\\Downloads\\\\Lending-company.csv\"\n",
    "load_file = np.genfromtxt(lend_co,delimiter=',',dtype = str)\n",
    "# print(load_file)\n",
    "# saving data to the PC\n",
    "np.save('lending-saving-by-numpy',load_file)\n",
    "# loading the data\n",
    "saved_file=np.load('lending-saving-by-numpy.npy')\n",
    "print(saved_file)\n",
    "# to ensure both files are identical, we can use the array_equal function and plug in both datasets as inputs.\n",
    "np.array_equal(load_file,saved_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d5d1f6-e8d2-49ec-a7c0-eeeb7880df4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# different ways to externally store data - numpy functions to save python data into files : np.savez()\n",
    "# new function file type works best with multiple arrays - .npz. its like an archive of NPYs that can store multiple arrays.\n",
    "# hence instead of storing different datasets in separate NPY files, we can store all of them in a single NPZ\n",
    "# NPZ files store each dataset as a separate array. - to set custom name, by keyword args for each array\n",
    "import numpy as np\n",
    "lend_co = \"C:\\\\Users\\\\TJO1COB\\\\Downloads\\\\Lending-Company-Saving.csv\"\n",
    "load_company = np.genfromtxt(lend_co,delimiter=',', dtype=str)\n",
    "print(load_company)\n",
    "\n",
    "saved_file=np.load('lending-saving-by-numpy.npy')\n",
    "np.savez('Lending-Company-Saving',saved_file,lend_co)\n",
    "# load npz just created, syntax quite similar\n",
    "lending_savez_load = np.load('Lending-Company-Saving.npz')\n",
    "print(\"savez : \\n \",lending_savez_load[\"arr_0\"]) #to want the first one, we must specify arr_0 - this tells python to pull the array with index 0 from the lending_savez_load variable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3027aa46-5744-41cc-bae4-4d5dd33a3ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a new NPZ with custom file names:\n",
    "np.savez('Lending-Company-Saving',file_1_npz = saved_file,file_2_npz=lend_co)\n",
    "# reload after creating a new npz\n",
    "npz_loads=np.load('Lending-Company-Saving.npz')\n",
    "# after saving and reloading, we can check the files attribute to see the file names inside the NPZ\n",
    "npz_loads.files\n",
    "print(npz_loads[\"file_1_npz\"])\n",
    "print(\"\\n\")\n",
    "print(npz_loads[\"file_2_npz\"])\n",
    "np.array_equal(npz_loads['file_1_npz'],npz_loads['file_2_npz'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3a16cb-873c-41cb-9f2a-52538874fdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving data into text files with np.txt() function - np.savetxt() helps store datasets in text files as .txt or .csv \n",
    "import numpy as np\n",
    "lend_co = \"C:\\\\Users\\\\TJO1COB\\\\Downloads\\\\Lending-Company-Saving.csv\"\n",
    "load_company = np.genfromtxt(lend_co,delimiter=',', dtype=str)\n",
    "save_txt = np.savetxt(\"Lending-Company-Saving.txt\", load_company,fmt='%s',delimiter=',')\n",
    "load_txt = np.genfromtxt(\"Lending-Company-Saving.txt\",delimiter=',', dtype=str)\n",
    "load_txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc361e9-4b40-4a88-8bd8-e9e6c4b6d389",
   "metadata": {},
   "source": [
    "Working with text data - need to convert text data into appropriate format. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a5ed58-8ecd-41d0-a48f-380363603378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# argument specifier %s is for inserting strings, %d is for inserting integers\n",
    "Product_Category = [\"A\",\"T\"]\n",
    "print('Name of the Category is \"%s\" ' % Product_Category[1])\n",
    "quantities = [23,45,67]\n",
    "print(\"Quantity is '%d' of Trinita\" % quantities[2])\n",
    "quantities_f = [23.34,45.76,67]\n",
    "print(\"Float Quantity is '%.30f' of Trinita\" % quantities_f[0])\n",
    "print (\"\\n\")\n",
    "i=1\n",
    "print(\"Product Category %s is of quantity '%d' with float value of '%.4f' \" %(Product_Category[i] ,quantities[i], quantities_f[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531d3286-137c-451c-84c8-02ad997acecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manipulating python strings\n",
    "print(\"Trini is 23\")\n",
    "print(\"Trini \\nis \\n23\")\n",
    "print('Trini:\\tis 23 years old')\n",
    "# carriage return \\r - carry all subsequent strings to the start of the string\n",
    "print(\"23 years old 'Trini'. \\r24\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b11ed64-f677-4ef2-8a37-d7bcd75d6b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_shop = [\"Fast Cars\", \"Elegant Cars\"]\n",
    "car_brand = ['Audi', 'Ford']\n",
    "number_of_cars_for_sale = [1000, 1200]\n",
    "price_of_model = 37500.50\n",
    "print('Current list of local car shops:\\n\"%s\"\\n\"%s\"' %(car_shop[0],car_shop[1]))\n",
    "\n",
    "print('Current list of local car shops: \\n\"%s\" \\n\"%s\"' %(car_shop[0],car_shop[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c49c4c-cea5-41ab-926e-88f870f33dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Product A1 is our best category of products. \\rCategory A \" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c029dce6-5bd1-4a77-bf3a-975dcc3b820c",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_shop = ['Fast Cars', 'Elegant Cars']\n",
    "car_brand = ['Audi', 'Ford']\n",
    "number_of_cars_for_sale = [1000, 1200]\n",
    "price_of_model = 37500.50\n",
    "print('The \"%s\" shop are expecting to sell %d units of the new %s  model next year. The \"%s\" shop are expecting to sell %d units of the new %s model next year.'\n",
    "\n",
    "%(car_shop[0],number_of_cars_for_sale[0],car_brand[0],car_shop[0],number_of_cars_for_sale[1],car_brand[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bcc811-7493-4c5c-b0c7-2951bfd2c612",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_shop = ['Fast Cars', 'Elegant Cars']\n",
    "car_brand = ['Audi', 'Ford']\n",
    "number_of_cars_for_sale = [1000, 1200]\n",
    "price_of_model = 37500.50\n",
    "\n",
    "print (\"The \\\"%s\\\" shop are expecting to sell %d units of the new %s model next year.\" % (car_shop[0], number_of_cars_for_sale[0], car_brand[0]) + \"\\t\" \n",
    "       \" The \\\"%s\\\" shop are expecting to sell %d units of the new %s model next year.\" % (car_shop[1], number_of_cars_for_sale[1], car_brand[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156710bd-9fde-4afe-8359-2e0695034090",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_shop = ['Fast Cars', 'Elegant Cars']\n",
    "car_brand = ['Audi', 'Ford']\n",
    "number_of_cars_for_sale = [1000, 1200]\n",
    "price_of_model = 37500.50\n",
    "\n",
    "i=0\n",
    "print(\"The \\\"%s\\\" shop are expecting to sell %d units of the new %s model at %.2f per unit next year.\" % (car_shop[i], number_of_cars_for_sale[i], car_brand[i],price_of_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cff513-43b2-4570-987c-dd38855ba439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# String methods - is a text manipulation technique that differs from working with arg specifiers\n",
    "# 1. replace method\n",
    "name_1 = \"TRINI IS SOON 23 YEARS OLD\"\n",
    "replaced_name_1 = name_1.replace('YEARS',\"YRS\")\n",
    "replaced_name_1\n",
    "# 2.startswith and endswith method\n",
    "name_1.startswith('T')\n",
    "name_1.endswith('D')\n",
    "# 3. split() - splits a string and returns a list with values separated\n",
    "name_1.split(' ',1) #1 means want a single split - watch the commas for the split as it is only taken into consideration.\n",
    "name_2 = 'TRINI,PAULINE,HARI'\n",
    "name_2.split(',')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5758aeb6-7a15-402d-b8d6-20863ad020fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'Administrative expenses'\n",
    "print(s.startswith(\"Admin\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e123c83-a73e-49c9-a306-53983be45cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "s2 = \"personal ID, first name, last name, date of birth, place of birth, city of birth\"\n",
    "list_01 = s2.split()\n",
    "print(list_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0507748-ff35-4c3f-afae-dca150c11d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STRING METHODS - to change the case of the character(upper,lower methods); stripping of characters.\n",
    "name_3 = 'TRIni, IS 23 old'\n",
    "print(name_3.title()) \n",
    "# title method can be implemented on a string object directly\n",
    "'trini is'.title()\n",
    "'trini is'.capitalize()\n",
    "# name_3.capitalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a94514-d0d9-4cc4-aa0d-3b0975dd6d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# strip method removes whitespaces at the start and end of the string by default\n",
    "name_4 = \" quarterly report \"\n",
    "name_4.strip(' quarorty ') \n",
    "# lstrip and rstrip for left and right strips\n",
    "# name_4.rstrip(' L')\n",
    "# spc_charac = \" !@#$$abcdefgh \"\n",
    "# spc_charac.strip(' !@abcdefgh ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdc2c62-6af8-4488-9422-0359155d4b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "name1 = 'Martin Peterson   '\n",
    "print(name1.rstrip(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5518ef67-4659-4b1c-99e6-3f84d66bcb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STRING ACCESSORS str - working with text data in pandas series\n",
    "import pandas as pd\n",
    "operational_kpis = pd.Series([\" employee rating \", \"employee performance \"])\n",
    "operational_kpis[1].rstrip(\" \")\n",
    "# pd.Series([operational_kpis[0].lstrip(\" \"),operational_kpis[1].rstrip(\" \")])\n",
    "# operational_kpis.str[1]\n",
    "operational_kpis.str.lstrip(' employee')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27e2286-0f94-4642-8efd-81283cb5951d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lstrip() method is not to be applied on the numeric value, hence missing value will be obtained.\n",
    "import pandas as pd\n",
    "test_string = pd.Series([\"Text_data\",'34'])\n",
    "test_string.str.lstrip(\"T\")\n",
    "# contains method\n",
    "housing_prices = pd.Series(['$300,000','$600,000','$700,000'])\n",
    "housing_prices.str.contains(\"$000\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7afc5be-a6de-4f0f-8a14-6e0bc280e0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to remove the first names in the series \n",
    "import pandas as pd; \n",
    "names = pd.Series([\"Martin Peterson\", \"John Fitzpatrick\", \"Kate Cruz\"])\n",
    "last_name = names[1].split()\n",
    "print(last_name)\n",
    "# or\n",
    "import pandas as pd;\n",
    "names = pd.Series([\"Martin Peterson\", \"John Fitzpatrick\", \"Kate Cruz\"])\n",
    "last_names = names.str.split(' ').str[1]\n",
    "print(last_names)\n",
    "type(last_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a8dc8f-e48d-4b3b-b5de-feb9928b65d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "names = pd.Series([\"Martin Peterson\", \"John Fitzpatrick\", \"Kate Cruz\"])\n",
    "last_names = names.str.split().str[1]\n",
    "print(last_names.str.contains(\"s\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4075c496-f9fd-4b8e-8d5a-b70bed4e08ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .format() method is applicable to string values only. this can be used without print statements.\n",
    "# {} - are placeholders where we insert the values been passed as arguments of .format() method\n",
    "Names=['TRINI', 'MOM']\n",
    "Ages = 23,49\n",
    "'Age of {}, Marias daughter is {}'.format('TRINI',23)\n",
    "# to replace entire tuple and list: positional args\n",
    "i=0\n",
    "'Age of {}, Marias daughter is {}'.format(Names[i],Ages[i])\n",
    "# There are 2 types of parameters : positional and keyword.\n",
    "# using keyword arguments :\n",
    "'Age of {n[0]}, Marias daughter is {a}'.format(n=['TRINI','MOM'],a=23)\n",
    "'Age of {n[0]}, Marias daughter is {a[0]} who are a family of {two}'.format(n=Names,a=Ages,two=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08156659-d445-47fa-ae35-427fad0da6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{} expects their next year's sales of Q{} to {}.\".format('Comapany A',3,'increase'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f842cd-20a2-4278-b566-7683e5859d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# range function - generates a sequence\n",
    "for i in range(3):\n",
    " for j in range(3):\n",
    "    \n",
    "    print(i,end=\"}\")\n",
    "    print (\"i\\nok\")\n",
    "    print(j)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56618150-4dca-49e1-b9e5-7d0da4b951ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "ran=list(range(10))\n",
    "ran\n",
    "for i in range(9):\n",
    "    print(i,end = \"\\n. \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29b0578-54be-4d04-aa08-541b98943fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "products_on_sale = ['Chair_Type_1', 'Chair_Type_2', 'Chair_Type_3', 'Chair_Type_4']\n",
    "sale_prices = [100, 120, 135, 150]\n",
    "quantities = [1000, 1500, 1300]\n",
    "for i in products_on_sale:\n",
    "    for j in sale_prices:\n",
    "        for k in quantities:\n",
    "            print(\"Expected revenue for {0} if {1} chairs are to be sold: {sales}\".format(i, k, sales = j*k))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63adbce-e494-4987-b98a-6f59ed020790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list comprehensions\n",
    "num = [2,4,5]\n",
    "num2=[]\n",
    "for i in num:\n",
    "    a=i*i\n",
    "    num2.append(a)\n",
    "num2\n",
    "# or --using output expression as an iterable\n",
    "num2= [i*i for i in num]\n",
    "num2\n",
    "# example 2\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        print(i+j,end=\" \")\n",
    "# or :\n",
    "num3 = [ i+j for i in range(2) for i in range(2)] \n",
    "type(num3)\n",
    "# lists as multidimensional lists\n",
    "lis_list = [[i+j] for i in range(2) for j in range(2)]\n",
    "lis_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e4baa7-20ed-423a-a12b-d7ee4ba170ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "products_on_sale = ['Chair_Type_1', 'Chair_Type_2', 'Chair_Type_3', 'Chair_Type_4']\n",
    "sale_prices = [100, 120, 135, 150]\n",
    "quantities = [1000, 1500, 1300]\n",
    "sales_revenue = [[chair_type,price*quantity] for quantity in quantities for price in sale_prices for chair_type in products_on_sale]\n",
    "for i in sales_revenue:\n",
    "    print(*i) \n",
    "#     When using the *i syntax, it skips printing the square brackets []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d12585-6fe8-4557-93d9-e022a5f12afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example 2 for list comprehension\n",
    "l2=[]\n",
    "for i in range(1,11):\n",
    "    if i%2 == 0:\n",
    "        a = i* 10\n",
    "        l2.append(a)\n",
    "print(l2,end=\" \")\n",
    "# or----------\n",
    "print([num * 10 for num in list(range(1, 11)) if num % 2 == 0])\n",
    "print([num * 10 if num % 2 == 0 else \"None\" for num in range(1, 11)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f87817-09c0-405a-961e-3b9e96bf1b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LAMBDA EXPRESSIONS : python syntax for creating anonymous functions\n",
    "def power_raise_to_2(x):\n",
    "    return x**2\n",
    "power_raise_to_2(3)\n",
    "lambda x : x**2 #this shows only that there is a lamba function \n",
    "# hence assigning the expression to lambda function will do the job\n",
    "power_raise_to_2_lambda = lambda x : x**2\n",
    "power_raise_to_2_lambda(3)\n",
    "# example 2 of lambda\n",
    "(lambda w : w==9)(9)\n",
    "# can pass multiple arguments to lambda functions but has to contain a single expression only:\n",
    "(lambda e,r: e+r) (3,9)\n",
    "# example 3:\n",
    "func_xy = lambda x,y : x+y(x) # y is a function of x here, hence passing 2 args or 1 to to the func_xy will result in error. \n",
    "# therefore, value of y should be a function:\n",
    "func_xy(2,lambda x : x*3)\n",
    "# example 4:\n",
    "multiply_by_10 = lambda x : x*10 \n",
    "multiply_by_10(7)\n",
    "# example 5 :Create a Lambda function that returns the output of the following mathematical expression. Execute it with an argument of 3 : ((135-(x**3))**4) / (1+x)**5\n",
    "( lambda x : ((135-(x**3))**4) / (1+x)**5 ) (3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734b31e2-36fd-400d-ba02-db154914941f",
   "metadata": {},
   "source": [
    "DATA GATHERING/DATA COLLECTION : obtaining high quality data should be a priority. \n",
    "Data can be classified into 2 types: primary(meaning creating the data eg, where respondants provide answer to your surveys. In business context, companies create data all the time) and secondary (existing data created by somebody else).\n",
    "Downloading data which is online and in unpackaged file form. This can be acheived in 2 ways - web scraping and APIs.\n",
    "web scraping - request the webpage from a server -> extract data from a HTML format that is sent. Example of web scraping - managing the youtube live count -> request the page and extract the value of interest from the python script. Disadvantages : 1. not reliable or scalable (will have to constantly maintain code coz any small change could result in breakage of scraper; each page has a different HTML structure hence the code written has to be changed accordingly) 2. legality (if website explicitly mentions no web scraping, doing it can end up in court). Considering all of these, web scraping is an important in Data Collection when all other options are off the table. \n",
    "API's are desgined for programmatical data exchange. They provide data of format .CSV and .json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ee068c-762f-4ddc-a42f-f1fafea51de6",
   "metadata": {},
   "source": [
    "APIs :\n",
    "HTTP - hypertext transfer protocol is a way in which information is exchanged on the internet; it specifies how requests are to be formatted and transmitted; websites have a collection of file - the HTML code for this website is saved on a remote machine like server in the form of files. while surfing, we download these files and use browser to display the info. This is processed by a `Request` and responds accordingly.\n",
    "2 most popular HTTP requests : GET & POST. \n",
    "GET - obtains data from server, can be bookmarked, parameters can be added to URL directly, not used for sensitive information.\n",
    "POST - used to alter and send confidential info. For eg, login credentials can be transmitted through a POST request.\n",
    "To indicate the successful response of a request, status code is 200 and 404 for error. When the response is successful the body data can be extracted. if its a webpage, data is HTML file, web api - common format to transmit data is json.\n",
    "JSON java script object orientation is a standard format for data exchange. when gets requests are sent to APIs, the data is returned in the form of JSON. the payload data of a post request is also a JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9461e3f8-ec14-49e0-874b-a5576cb7c7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXCHANGE RATES API\n",
    "import requests\n",
    "base_url = \"https://api.exchangeratesapi.io/latest\" ## Base URL: the part of the URL common to all requests, not containing the parameters\n",
    "# send get request\n",
    "response = requests.get(base_url)\n",
    "# investigating response\n",
    "response.ok #or response.status_code\n",
    "response.text #.text returns it as regular string and .content returns the data in bytes format\n",
    "response.content\n",
    "# handling the JSON - `requests` library provides us with .json() method to convert data to python object.\n",
    "response.json\n",
    "# TRANSFORMATION WITH type function\n",
    "type(response.json) #should give a dict\n",
    "# to enhance the readability json package can be used which provides methods for data manipulation. 2 main are : loads which converts json format string to python object, dumps which converts python object back to regular string.\n",
    "import json\n",
    "# set indentation\n",
    "print(json.dumps(response.json(), indent=3))\n",
    "print(json.dumps(response.json()))\n",
    "# inspect contents of JSON\n",
    "response.json().keys()\n",
    "\n",
    "# sending parameters to filter the response example : http://....?par1=value1&par2=value2\n",
    "par_url = base_url + \"?symbols=CAD,USD\"\n",
    "print(par_url)\n",
    "response_2 = requests.get(par_url)\n",
    "response_2\n",
    "data_2 = response.json()\n",
    "print(data_2)\n",
    "data_2[\"success\"]\n",
    "param_url = base_url + \"?symbols=GBP\" + \"&\" + \"base=USD\"\n",
    "data = requests.get(param_url).json()\n",
    "data\n",
    "get_data = requests.get(param_url).json()\n",
    "print(json.dumps(get_data,indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a6324a-f6b4-4041-b5ec-f556b1aecf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.path)\n",
    "json_data = {'rates' : {'GBP' : 0.77}, 'base' : 'usd', 'date': '2020/6/12'}\n",
    "json_data2 = json_data[\"rates\"][\"GBP\"]\n",
    "json_data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60042f53-2c23-45e4-a253-e27fa2276ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# building a simple currency conversion calculator : gather parameters of interest, construct a URL and send get request to it, print out error message where applicable\n",
    "\n",
    "data = input(\"enter input (format - 'yyyy-mm-dd')\")\n",
    "base = input(\"convert from (currency)\")\n",
    "cur = input(\"convert to (currency)\")\n",
    "quantity = float(input(\"enter how much {} to convert\".format(base)))\n",
    "\n",
    "get_url = base_url + \"/\" + date + \"?base=\" + base + \"&symbols=\" + cur\n",
    "out = requests.get(get_url)\n",
    "\n",
    "if response.ok is false:\n",
    "    print(\"\\nError{}:\".format(response.status_code))\n",
    "    print(response.json()['error'])\n",
    "else :\n",
    "    data = response.json()\n",
    "    rate = data['rates'][curr]\n",
    "    result = quantity*rate\n",
    "    \n",
    "    print(\"\\n{0} {1} is equal to {2} {3}, based upon exchange rates on {4}\".format(base,quantity,result,cur,data['date']))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48282ab1-56ef-4a5a-b09e-53cefc722ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ITUNES SEARCH API\n",
    "import json,requests\n",
    "itunes_url = \"https://itunes.apple.com/search\"\n",
    "url = itunes_url + \"?term=thebeatles&country=us\"\n",
    "requests.get(url)\n",
    "# can aslo give paramters in the URL - this way of appending paramters is actually the preferred one\n",
    "r = requests.get(itunes_url, params={\"term\":\"the beatles\",\"country\":\"us\"})\n",
    "r.status_code\n",
    "r.url\n",
    "data = r.json()\n",
    "data.keys() #to get only keys from the data, instead of loading the full data and inspecting from that\n",
    "# print(json.dumps(data['results'][1], indent=4))\n",
    "data[\"resultCount\"]\n",
    "# we can set the result to maximum of 200 by adding the limit paramter\n",
    "lmt = requests.get(itunes_url, params={\"term\":\"the beatles\",\"country\":\"us\",\"limit\":200})\n",
    "lmt.ok\n",
    "lmt.json()[\"resultCount\"]\n",
    "# finally check the behaviour of this API to invalid paramters\n",
    "inv = requests.get(itunes_url, params={\"term\":\"invalid\",\"country\":\"none\"})\n",
    "print(\"status code is {}\".format(inv.status_code))\n",
    "inv.json()\n",
    "\n",
    "# -----------------\n",
    "\n",
    "# structuring and exporting the data obtained with the help of Dataframe class from Pandas module which is a structured data in a tabular format\n",
    "import pandas as pd\n",
    "df_data = pd.DataFrame(data[\"results\"])\n",
    "df_data\n",
    "\n",
    "#exporting data into a csv file using the .to_csv() method\n",
    "into_csv = df_data.to_csv(\"results.csv\")\n",
    "into_csv\n",
    "    \n",
    "#exporting data into an excel file using the .to_excel() method\n",
    "into_xl = df_data.to_excel(\"results.xlsx\")\n",
    "into_xl\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0caf70d-78b5-49ce-81d7-c3086f6e62a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8922f0dd-0ba4-491f-a4f0-a40ef5aee57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PAGINATION - content separated in portions - pages. many APIs also deliver their data in pages\n",
    "# example - github jobs API\n",
    "import requests,json\n",
    "g_api = \"https://jobs.github.com/api\"\n",
    "# set parameters\n",
    "s=requests.get(g_api,params={\"description\":\"data science\",\"location\":\"los angeles\"})\n",
    "s.status_code\n",
    "r.json()\n",
    "len(s.json)\n",
    "# search without aplying any filters - remove params in the requests object\n",
    "r = requests.get(g_api, params={\"page\":2})\n",
    "r.status_code\n",
    "r.json()\n",
    "len(r.json())\n",
    "\n",
    "# extracting results from first 5 pages:\n",
    "# define an empty list that will be filled with extracted result\n",
    "result = []\n",
    "for i in range(5):\n",
    "    req=requests.get(g_api, params = {\"page\":i+1})\n",
    "    if len(req.json() == 0:\n",
    "           break\n",
    "    else:\n",
    "        result.extend(r.json())\n",
    "len(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0756d3-a126-4ec5-aef0-efbe2e5b1fea",
   "metadata": {},
   "source": [
    "DATA CLEANING AND DATA PREPROCESSING :\n",
    "Applying certain analyical and programming techniques to convert incomprehensible dataset into quality format that can be used for further processing(statistical and mathematical computations).\n",
    "This process ensures dataset is \"Deprived of inconsistencies\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fea6edde-5f51-4040-8842-a041fe77e32b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\TJO1COB'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5d8f4460-c6bb-4e6c-ae1c-dfc84bf24443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LoanID            1043\n",
       "StringID          1043\n",
       "Product              6\n",
       "CustomerGender       3\n",
       "Location           296\n",
       "Region              18\n",
       "TotalPrice           9\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pandas series - .unique() and .nunique()\n",
    "# importing a csv file using the pd.read_csv() method\n",
    "import pandas as pd\n",
    "data_1 = pd.read_csv('Lending-Company-Saving.csv',squeeze=True) #the sqeeze parameter in this method converts the data into pandas series instead of dataframe if data consists of only one column.\n",
    "data_2=data_1.copy()\n",
    "print(type(data_2))\n",
    "data_2.head()\n",
    "data_2.describe()\n",
    "len(data_2)\n",
    "# nunique method in pandas retrieves number of unique values from the dataset.\n",
    "data_2.nunique() # extract the number of unique values from the Series.\n",
    "# obtain an array containing all unique values from the region_data Series ->use the unique method\n",
    "type(data_2.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ba83b108-f21c-4497-8a8f-49f786f4bac3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([30., 50.])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting series into numpy arrays\n",
    "import pandas as pd\n",
    "sa = pd.Series({'Product A' : 30, 'Product B' : 50, 'Product C' : 70}) #creating a series object then accessing its attributes\n",
    "# all the below 3 usages return same output -> using the values attribute is not fully recommended as per official documentation site.\n",
    "sa.values\n",
    "sa.array\n",
    "sa.to_numpy()\n",
    "\n",
    "# \n",
    "c_float = sa[['Product A', 'Product B']].to_numpy(dtype=float)\n",
    "c_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "31452ac7-50d8-4850-a9ed-c6282fa5727d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.sort_values of    LoanID StringID    Product CustomerGender    Location    Region  TotalPrice\n",
       "0       1     id_1  Product B           Male  Location 2  Region 2     16600.0\n",
       "1       2     id_2  Product B           Male  Location 3       NaN     16600.0\n",
       "2       3     id_3  Product C         Female  Location 5  Region 5     15600.0\n",
       "3       4     id_4  Product B           Male  Location 6  Region 1     16600.0\n",
       "4       5     id_5  Product D         Female  Location 7  Region 2     20250.0>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort_values() method to obtain sorted values of a series in ascending order, there is a paramter of this value that provides a descending order sort too\n",
    "# create a series object\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "num_ser = pd.Series([2098,4576,1754])\n",
    "num_ser.sort_values(ascending=False)\n",
    "# application of sort value \n",
    "dataset = pd.read_csv('Lending-Company-Saving.csv', squeeze=True)\n",
    "dc = dataset.copy()\n",
    "\n",
    "dh=dc.head()\n",
    "dh.sort_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d8cb36e0-4a18-4ca1-8b23-ef9bad92519a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0    1    2 ... 1040 1041 1042]\n"
     ]
    }
   ],
   "source": [
    "# Attribute and method chaining for manipulating data. Attribute chaning allows to refre the values obtained by different attributes, and so is for method chaning. It organises and applies several method calls on a certain object in the given order\n",
    "# one advantange of this technique is we do not require to explicitly store the immediately obtained output - saves time of creating a variable.\n",
    "import pandas as pd\n",
    "iit = pd.read_csv('Lending-Company-Saving.csv', squeeze=True)\n",
    "act = iit.copy()\n",
    "act.head()\n",
    "act.index\n",
    "act.index.name = 'SAMPLE NAME'\n",
    "act.index.name # is the name of the series dataset\n",
    "# act.sort_values().tail() #chaining the tail method\n",
    "act.index.to_numpy()\n",
    "# Obtain the row labels of the index i.e. use values, stored in an array. example :\n",
    "print(act.index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c2ef7117-5aff-4f5b-b87b-00c5e978bb58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Series.keys of No_0001    1963-08-02\n",
      "No_0002    1964-06-13\n",
      "No_0003    1989-12-04\n",
      "No_0004    1996-04-08\n",
      "dtype: object>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "emp_birth_date = pd.Series({'No_0001':'1963-08-02', 'No_0002':'1964-06-13', 'No_0003':'1989-12-04', 'No_0004':'1996-04-08'})\n",
    "print(emp_birth_date.keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d4b535-526c-441d-9e06-3ce04ab3c6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort_index\n",
    "# just use this method with same ascending parameter like sort_values() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f53e4c52-e646-4ec0-905c-80757a683058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array is\n",
      "[[3 6 5]\n",
      " [4 2 7]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col 1</th>\n",
       "      <th>col 2</th>\n",
       "      <th>col 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>row 1</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row 2</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      col 1 col 2 col 3\n",
       "row 1     3     6     5\n",
       "row 2     4     2     7"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DATAFRAME - IT CORRESPONDS TO 2-D NUMY ARRAY; ALSO IS A TABULAR STRUCTURE CONATINING MULTIPLE OBSERVATIONS FOR A GIVEN SET OF VARIABLES. IT'S 2-DIMENSIONAL ( 2 points with row and columns). Every column from the dataframe is a series object itself.\n",
    "# DATAFRAME RETROSPECTION\n",
    "# CREATE AN ARRAY THEN CHANGE IT INTO A DATAFRAME - to create with different lenghts and shapes, use the dtype parameter of array datastructure.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df=np.array([[3,6,5],[4,2,7]],dtype=object) \n",
    "# df_1 = pd.DataFrame(df)\n",
    "type(df)\n",
    "print(\"array is\")\n",
    "print(f\"{df}\")\n",
    "#type func confirms that the object is a df\n",
    "# when not explicit about the index and column names while creating the dataframe, default integer indexing will be assinged to both. provide column labels using column paramter and row labels using the index paramter.\n",
    "df_2 = pd.DataFrame(df,columns=['col 1', 'col 2', 'col 3'], index=['row 1','row 2'])\n",
    "df_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34a186e4-3c7b-48b9-ac84-f223995091fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       StringID    Product CustomerGender      Location    Region  TotalPrice\n",
      "LoanID                                                                       \n",
      "1039    id_1039  Product B         Female   Location 39  Region 6     16600.0\n",
      "1040    id_1040  Product B           Male   Location 50  Region 1         NaN\n",
      "1041    id_1041  Product B           Male   Location 23  Region 4     16600.0\n",
      "1042    id_1042  Product C   NotSpecified   Location 52  Region 6     15600.0\n",
      "1043    id_1043  Product B         Female  Location 142  Region 6     16600.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Int64Index([   1,    2,    3,    4,    5,    6,    7,    8,    9,   10,\n",
       "            ...\n",
       "            1034, 1035, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1043],\n",
       "           dtype='int64', name='LoanID', length=1043)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exporting external dataframe into pandas dataframe \n",
    "# attributes in pandas dataframe\n",
    "import pandas as pd\n",
    "data = pd.read_csv(r\"C:\\\\Users\\\\TJO1COB\\\\Lending-Company-Saving.csv\", index_col='LoanID') #assigning load ID as index column\n",
    "cd = data.copy()\n",
    "type(cd)\n",
    "# cd.head(), tail(), describe(),copy(), \n",
    "print(cd.tail())\n",
    "# attributes for working with dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "83b8b055-07af-454d-a4a7-84b17f70715e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([   1,    2,    3,    4,    5,    6,    7,    8,    9,   10,\n",
       "            ...\n",
       "            1034, 1035, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1043],\n",
       "           dtype='int64', name='LoanID', length=1043)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cd.index # to get number of rows present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d332f1d-c658-4f77-b0cb-42c3d57fc717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Int64Index([   1,    2,    3,    4,    5,    6,    7,    8,    9,   10,\n",
       "             ...\n",
       "             1034, 1035, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1043],\n",
       "            dtype='int64', name='LoanID', length=1043),\n",
       " Index(['StringID', 'Product', 'CustomerGender', 'Location', 'Region',\n",
       "        'TotalPrice'],\n",
       "       dtype='object')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(cd.columns)\n",
    "cd.axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3cf6029b-40e6-41e3-9536-ed2fb3f7dc7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['StringID', 'Product', 'CustomerGender', 'Location', 'Region',\n",
       "       'TotalPrice'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cd.columns # to get all column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46245c10-ab8c-408c-8d95-94f5cc1db565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StringID           object\n",
       "Product            object\n",
       "CustomerGender     object\n",
       "Location           object\n",
       "Region             object\n",
       "TotalPrice        float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# another attribute of the pandas dataframe is the dtypes - it displays all column names to the left and corresp datatypes to the right\n",
    "cd.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8c9dcaa9-5c4e-4866-ba9c-871cacced0bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['id_1', 'Product B', 'Male', 'Location 2', 'Region 2', 16600.0],\n",
       "       ['id_2', 'Product B', 'Male', 'Location 3', nan, 16600.0],\n",
       "       ['id_3', 'Product C', 'Female', 'Location 5', 'Region 5', 15600.0],\n",
       "       ...,\n",
       "       ['id_1041', 'Product B', 'Male', 'Location 23', 'Region 4',\n",
       "        16600.0],\n",
       "       ['id_1042', 'Product C', 'NotSpecified', 'Location 52',\n",
       "        'Region 6', 15600.0],\n",
       "       ['id_1043', 'Product B', 'Female', 'Location 142', 'Region 6',\n",
       "        16600.0]], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cd.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "11954051-2459-4ce1-a009-de9e3f7240cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.value_counts of        StringID    Product CustomerGender      Location    Region  TotalPrice\n",
       "LoanID                                                                       \n",
       "1          id_1  Product B           Male    Location 2  Region 2     16600.0\n",
       "2          id_2  Product B           Male    Location 3       NaN     16600.0\n",
       "3          id_3  Product C         Female    Location 5  Region 5     15600.0\n",
       "4          id_4  Product B           Male    Location 6  Region 1     16600.0\n",
       "5          id_5  Product D         Female    Location 7  Region 2     20250.0\n",
       "...         ...        ...            ...           ...       ...         ...\n",
       "1039    id_1039  Product B         Female   Location 39  Region 6     16600.0\n",
       "1040    id_1040  Product B           Male   Location 50  Region 1         NaN\n",
       "1041    id_1041  Product B           Male   Location 23  Region 4     16600.0\n",
       "1042    id_1042  Product C   NotSpecified   Location 52  Region 6     15600.0\n",
       "1043    id_1043  Product B         Female  Location 142  Region 6     16600.0\n",
       "\n",
       "[1043 rows x 6 columns]>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(cd.values)\n",
    "cd.value_counts #return a Series containing counts of unique rows in the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7afb6304-4697-4153-a4a7-fce4a58cf3e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['id_1', 'Product B', 'Male', 'Location 2', 'Region 2', 16600.0],\n",
       "       ['id_2', 'Product B', 'Male', 'Location 3', nan, 16600.0],\n",
       "       ['id_3', 'Product C', 'Female', 'Location 5', 'Region 5', 15600.0],\n",
       "       ...,\n",
       "       ['id_1041', 'Product B', 'Male', 'Location 23', 'Region 4',\n",
       "        16600.0],\n",
       "       ['id_1042', 'Product C', 'NotSpecified', 'Location 52',\n",
       "        'Region 6', 15600.0],\n",
       "       ['id_1043', 'Product B', 'Female', 'Location 142', 'Region 6',\n",
       "        16600.0]], dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to convert a dataframe to numpy 2 dimensional array - use the to_numpy() : this produces identical output to .values\n",
    "cd_numpy = cd.to_numpy()\n",
    "cd_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3a80a07b-a576-49fa-b3e0-3aaee557c5d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1043, 6)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# last attribute is the shape - retrieves a tuple \n",
    "cd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b984b034-68ab-4178-9d12-db4b2f8d6051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1043"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cd.columns)\n",
    "len(cd.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2b3265ac-cfca-426e-9ac9-6fbad2fd3453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['LoanID', 'Product', 'CustomerGender', 'Location', 'Region',\n",
       "       'TotalPrice'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# indexing elements - selecting a sepcific entry or subset can be done by indexing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "ds_c = pd.read_csv(r\"C:\\\\Users\\\\TJO1COB\\\\Lending-Company-Saving.csv\", index_col='StringID')\n",
    "ds = ds_c.copy()\n",
    "ds.index\n",
    "ds.values\n",
    "ds.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1fe3942c-45f7-4668-9d6c-cfc9009336e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StringID\n",
      "id_1          1\n",
      "id_2          2\n",
      "id_3          3\n",
      "id_4          4\n",
      "id_5          5\n",
      "           ... \n",
      "id_1039    1039\n",
      "id_1040    1040\n",
      "id_1041    1041\n",
      "id_1042    1042\n",
      "id_1043    1043\n",
      "Name: LoanID, Length: 1043, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accessing data of a specific column - retrieve the data stored in a particular column\n",
    "ds.LoanID\n",
    "# specifying the column name in the square brackets, is considered more professional way as it will still display values if there are whitespace characters\n",
    "print(ds['LoanID'])\n",
    "type(ds['LoanID']) #this reinforces the statement that a dataframe column inhertis the characteristics of pandas series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "32410582-c1c2-4c36-a696-6049a24cde8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LoanID</th>\n",
       "      <th>Product</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>StringID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id_1</th>\n",
       "      <td>1</td>\n",
       "      <td>Product B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_2</th>\n",
       "      <td>2</td>\n",
       "      <td>Product B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_3</th>\n",
       "      <td>3</td>\n",
       "      <td>Product C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_4</th>\n",
       "      <td>4</td>\n",
       "      <td>Product B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_5</th>\n",
       "      <td>5</td>\n",
       "      <td>Product D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          LoanID    Product\n",
       "StringID                   \n",
       "id_1           1  Product B\n",
       "id_2           2  Product B\n",
       "id_3           3  Product C\n",
       "id_4           4  Product B\n",
       "id_5           5  Product D"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[['LoanID','Product']].head()\n",
    "type(ds)\n",
    "# more elegant way of obtaining the same result is to store the list in a a separate variable.\n",
    "l = ['LoanID', 'Product']\n",
    "ls = ds[l].head()\n",
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1650cb8d-c663-4059-8c9e-d3c092436bba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Platform</th>\n",
       "      <th>Year</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>NA_Sales</th>\n",
       "      <th>EU_Sales</th>\n",
       "      <th>JP_Sales</th>\n",
       "      <th>Other_Sales</th>\n",
       "      <th>Global_Sales</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rank</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wii Sports</td>\n",
       "      <td>Wii</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>41.49</td>\n",
       "      <td>29.02</td>\n",
       "      <td>3.77</td>\n",
       "      <td>8.46</td>\n",
       "      <td>82.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Super Mario Bros.</td>\n",
       "      <td>NES</td>\n",
       "      <td>1985.0</td>\n",
       "      <td>Platform</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>29.08</td>\n",
       "      <td>3.58</td>\n",
       "      <td>6.81</td>\n",
       "      <td>0.77</td>\n",
       "      <td>40.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mario Kart Wii</td>\n",
       "      <td>Wii</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>Racing</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>15.85</td>\n",
       "      <td>12.88</td>\n",
       "      <td>3.79</td>\n",
       "      <td>3.31</td>\n",
       "      <td>35.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wii Sports Resort</td>\n",
       "      <td>Wii</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>15.75</td>\n",
       "      <td>11.01</td>\n",
       "      <td>3.28</td>\n",
       "      <td>2.96</td>\n",
       "      <td>33.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pokemon Red/Pokemon Blue</td>\n",
       "      <td>GB</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>Role-Playing</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>11.27</td>\n",
       "      <td>8.89</td>\n",
       "      <td>10.22</td>\n",
       "      <td>1.00</td>\n",
       "      <td>31.37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Name Platform    Year         Genre Publisher  \\\n",
       "Rank                                                                      \n",
       "1                   Wii Sports      Wii  2006.0        Sports  Nintendo   \n",
       "2            Super Mario Bros.      NES  1985.0      Platform  Nintendo   \n",
       "3               Mario Kart Wii      Wii  2008.0        Racing  Nintendo   \n",
       "4            Wii Sports Resort      Wii  2009.0        Sports  Nintendo   \n",
       "5     Pokemon Red/Pokemon Blue       GB  1996.0  Role-Playing  Nintendo   \n",
       "\n",
       "      NA_Sales  EU_Sales  JP_Sales  Other_Sales  Global_Sales  \n",
       "Rank                                                           \n",
       "1        41.49     29.02      3.77         8.46         82.74  \n",
       "2        29.08      3.58      6.81         0.77         40.24  \n",
       "3        15.85     12.88      3.79         3.31         35.82  \n",
       "4        15.75     11.01      3.28         2.96         33.00  \n",
       "5        11.27      8.89     10.22         1.00         31.37  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# indexing with iloc[] - i - integer and loc - location - purely integer based location\n",
    "import pandas as pd\n",
    "csv1 = pd.read_csv('vgsales.csv',index_col='Rank')\n",
    "csv = csv1.copy()\n",
    "csv.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8bc8d766-d842-4e14-982a-24d66ada60f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name            Super Mario Bros.\n",
       "Platform                      NES\n",
       "Year                       1985.0\n",
       "Genre                    Platform\n",
       "Publisher                Nintendo\n",
       "NA_Sales                    29.08\n",
       "EU_Sales                     3.58\n",
       "JP_Sales                     6.81\n",
       "Other_Sales                  0.77\n",
       "Global_Sales                40.24\n",
       "Name: 2, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0f680e14-26c7-460c-9d41-d26673e4f78f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name            Mario Kart Wii\n",
       "Platform                   Wii\n",
       "Year                    2008.0\n",
       "Genre                   Racing\n",
       "Publisher             Nintendo\n",
       "NA_Sales                 15.85\n",
       "EU_Sales                 12.88\n",
       "JP_Sales                  3.79\n",
       "Other_Sales               3.31\n",
       "Global_Sales             35.82\n",
       "Name: 3, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv.iloc[2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "57038f10-1b26-4090-9715-bdddb766e314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(csv.iloc[:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9e73bc09-3e46-42d1-ba33-eecc3dde2a0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Platform</th>\n",
       "      <th>Year</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>NA_Sales</th>\n",
       "      <th>EU_Sales</th>\n",
       "      <th>JP_Sales</th>\n",
       "      <th>Other_Sales</th>\n",
       "      <th>Global_Sales</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rank</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mario Kart Wii</td>\n",
       "      <td>Wii</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>Racing</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>15.85</td>\n",
       "      <td>12.88</td>\n",
       "      <td>3.79</td>\n",
       "      <td>3.31</td>\n",
       "      <td>35.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pokemon Red/Pokemon Blue</td>\n",
       "      <td>GB</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>Role-Playing</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>11.27</td>\n",
       "      <td>8.89</td>\n",
       "      <td>10.22</td>\n",
       "      <td>1.00</td>\n",
       "      <td>31.37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Name Platform    Year         Genre Publisher  \\\n",
       "Rank                                                                      \n",
       "3               Mario Kart Wii      Wii  2008.0        Racing  Nintendo   \n",
       "5     Pokemon Red/Pokemon Blue       GB  1996.0  Role-Playing  Nintendo   \n",
       "\n",
       "      NA_Sales  EU_Sales  JP_Sales  Other_Sales  Global_Sales  \n",
       "Rank                                                           \n",
       "3        15.85     12.88      3.79         3.31         35.82  \n",
       "5        11.27      8.89     10.22         1.00         31.37  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# entire 2nd and 4th row\n",
    "data_selection = csv.iloc[[2,4],:]\n",
    "data_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a3809c28-9de1-4c97-8180-d83de09eae65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Platform</th>\n",
       "      <th>Year</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>NA_Sales</th>\n",
       "      <th>EU_Sales</th>\n",
       "      <th>JP_Sales</th>\n",
       "      <th>Other_Sales</th>\n",
       "      <th>Global_Sales</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rank</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mario Kart Wii</td>\n",
       "      <td>Wii</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>Racing</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>15.85</td>\n",
       "      <td>12.88</td>\n",
       "      <td>3.79</td>\n",
       "      <td>3.31</td>\n",
       "      <td>35.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pokemon Red/Pokemon Blue</td>\n",
       "      <td>GB</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>Role-Playing</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>11.27</td>\n",
       "      <td>8.89</td>\n",
       "      <td>10.22</td>\n",
       "      <td>1.00</td>\n",
       "      <td>31.37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Name Platform    Year         Genre Publisher  \\\n",
       "Rank                                                                      \n",
       "3               Mario Kart Wii      Wii  2008.0        Racing  Nintendo   \n",
       "5     Pokemon Red/Pokemon Blue       GB  1996.0  Role-Playing  Nintendo   \n",
       "\n",
       "      NA_Sales  EU_Sales  JP_Sales  Other_Sales  Global_Sales  \n",
       "Rank                                                           \n",
       "3        15.85     12.88      3.79         3.31         35.82  \n",
       "5        11.27      8.89     10.22         1.00         31.37  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# or this also works for the above usage\n",
    "csv.iloc[[2,4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1a9b8647-85ba-4b1e-97e8-939b1de07a3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16598, 10)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8a876b3d-fedc-4164-a50b-fa0bdc79a688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Publisher</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rank</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006.0</td>\n",
       "      <td>Nintendo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1985.0</td>\n",
       "      <td>Nintendo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008.0</td>\n",
       "      <td>Nintendo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009.0</td>\n",
       "      <td>Nintendo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1996.0</td>\n",
       "      <td>Nintendo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16596</th>\n",
       "      <td>2002.0</td>\n",
       "      <td>Kemco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16597</th>\n",
       "      <td>2003.0</td>\n",
       "      <td>Infogrames</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16598</th>\n",
       "      <td>2008.0</td>\n",
       "      <td>Activision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16599</th>\n",
       "      <td>2010.0</td>\n",
       "      <td>7G//AMES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16600</th>\n",
       "      <td>2003.0</td>\n",
       "      <td>Wanadoo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16598 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Year   Publisher\n",
       "Rank                     \n",
       "1      2006.0    Nintendo\n",
       "2      1985.0    Nintendo\n",
       "3      2008.0    Nintendo\n",
       "4      2009.0    Nintendo\n",
       "5      1996.0    Nintendo\n",
       "...       ...         ...\n",
       "16596  2002.0       Kemco\n",
       "16597  2003.0  Infogrames\n",
       "16598  2008.0  Activision\n",
       "16599  2010.0    7G//AMES\n",
       "16600  2003.0     Wanadoo\n",
       "\n",
       "[16598 rows x 2 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv.iloc[:,[2,4]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e39d2d93-7210-4bf1-aece-4b11b5ff4779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>NA_Sales</th>\n",
       "      <th>EU_Sales</th>\n",
       "      <th>JP_Sales</th>\n",
       "      <th>Other_Sales</th>\n",
       "      <th>Global_Sales</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Platform</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Wii</th>\n",
       "      <td>1</td>\n",
       "      <td>Wii Sports</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>41.49</td>\n",
       "      <td>29.02</td>\n",
       "      <td>3.77</td>\n",
       "      <td>8.46</td>\n",
       "      <td>82.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NES</th>\n",
       "      <td>2</td>\n",
       "      <td>Super Mario Bros.</td>\n",
       "      <td>1985.0</td>\n",
       "      <td>Platform</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>29.08</td>\n",
       "      <td>3.58</td>\n",
       "      <td>6.81</td>\n",
       "      <td>0.77</td>\n",
       "      <td>40.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wii</th>\n",
       "      <td>3</td>\n",
       "      <td>Mario Kart Wii</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>Racing</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>15.85</td>\n",
       "      <td>12.88</td>\n",
       "      <td>3.79</td>\n",
       "      <td>3.31</td>\n",
       "      <td>35.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wii</th>\n",
       "      <td>4</td>\n",
       "      <td>Wii Sports Resort</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>15.75</td>\n",
       "      <td>11.01</td>\n",
       "      <td>3.28</td>\n",
       "      <td>2.96</td>\n",
       "      <td>33.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GB</th>\n",
       "      <td>5</td>\n",
       "      <td>Pokemon Red/Pokemon Blue</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>Role-Playing</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>11.27</td>\n",
       "      <td>8.89</td>\n",
       "      <td>10.22</td>\n",
       "      <td>1.00</td>\n",
       "      <td>31.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GBA</th>\n",
       "      <td>16596</td>\n",
       "      <td>Woody Woodpecker in Crazy Castle 5</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>Platform</td>\n",
       "      <td>Kemco</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GC</th>\n",
       "      <td>16597</td>\n",
       "      <td>Men in Black II: Alien Escape</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>Shooter</td>\n",
       "      <td>Infogrames</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PS2</th>\n",
       "      <td>16598</td>\n",
       "      <td>SCORE International Baja 1000: The Official Game</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>Racing</td>\n",
       "      <td>Activision</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DS</th>\n",
       "      <td>16599</td>\n",
       "      <td>Know How 2</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>Puzzle</td>\n",
       "      <td>7G//AMES</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GBA</th>\n",
       "      <td>16600</td>\n",
       "      <td>Spirits &amp; Spells</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>Platform</td>\n",
       "      <td>Wanadoo</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16598 rows  10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Rank                                              Name    Year  \\\n",
       "Platform                                                                    \n",
       "Wii           1                                        Wii Sports  2006.0   \n",
       "NES           2                                 Super Mario Bros.  1985.0   \n",
       "Wii           3                                    Mario Kart Wii  2008.0   \n",
       "Wii           4                                 Wii Sports Resort  2009.0   \n",
       "GB            5                          Pokemon Red/Pokemon Blue  1996.0   \n",
       "...         ...                                               ...     ...   \n",
       "GBA       16596                Woody Woodpecker in Crazy Castle 5  2002.0   \n",
       "GC        16597                     Men in Black II: Alien Escape  2003.0   \n",
       "PS2       16598  SCORE International Baja 1000: The Official Game  2008.0   \n",
       "DS        16599                                        Know How 2  2010.0   \n",
       "GBA       16600                                  Spirits & Spells  2003.0   \n",
       "\n",
       "                 Genre   Publisher  NA_Sales  EU_Sales  JP_Sales  Other_Sales  \\\n",
       "Platform                                                                        \n",
       "Wii             Sports    Nintendo     41.49     29.02      3.77         8.46   \n",
       "NES           Platform    Nintendo     29.08      3.58      6.81         0.77   \n",
       "Wii             Racing    Nintendo     15.85     12.88      3.79         3.31   \n",
       "Wii             Sports    Nintendo     15.75     11.01      3.28         2.96   \n",
       "GB        Role-Playing    Nintendo     11.27      8.89     10.22         1.00   \n",
       "...                ...         ...       ...       ...       ...          ...   \n",
       "GBA           Platform       Kemco      0.01      0.00      0.00         0.00   \n",
       "GC             Shooter  Infogrames      0.01      0.00      0.00         0.00   \n",
       "PS2             Racing  Activision      0.00      0.00      0.00         0.00   \n",
       "DS              Puzzle    7G//AMES      0.00      0.01      0.00         0.00   \n",
       "GBA           Platform     Wanadoo      0.01      0.00      0.00         0.00   \n",
       "\n",
       "          Global_Sales  \n",
       "Platform                \n",
       "Wii              82.74  \n",
       "NES              40.24  \n",
       "Wii              35.82  \n",
       "Wii              33.00  \n",
       "GB               31.37  \n",
       "...                ...  \n",
       "GBA               0.01  \n",
       "GC                0.01  \n",
       "PS2               0.01  \n",
       "DS                0.01  \n",
       "GBA               0.01  \n",
       "\n",
       "[16598 rows x 10 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loc - referring to explicit index labels\n",
    "csv = pd.read_csv('vgsales.csv',index_col='Platform')\n",
    "csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e6471717-bcfe-4aa5-b939-1d5d875edaee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>NA_Sales</th>\n",
       "      <th>EU_Sales</th>\n",
       "      <th>JP_Sales</th>\n",
       "      <th>Other_Sales</th>\n",
       "      <th>Global_Sales</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Platform</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NES</th>\n",
       "      <td>2</td>\n",
       "      <td>Super Mario Bros.</td>\n",
       "      <td>1985.0</td>\n",
       "      <td>Platform</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>29.08</td>\n",
       "      <td>3.58</td>\n",
       "      <td>6.81</td>\n",
       "      <td>0.77</td>\n",
       "      <td>40.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NES</th>\n",
       "      <td>10</td>\n",
       "      <td>Duck Hunt</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>Shooter</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>26.93</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.47</td>\n",
       "      <td>28.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NES</th>\n",
       "      <td>23</td>\n",
       "      <td>Super Mario Bros. 3</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>Platform</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>9.54</td>\n",
       "      <td>3.44</td>\n",
       "      <td>3.84</td>\n",
       "      <td>0.46</td>\n",
       "      <td>17.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NES</th>\n",
       "      <td>97</td>\n",
       "      <td>Super Mario Bros. 2</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>Platform</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>5.39</td>\n",
       "      <td>1.18</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.19</td>\n",
       "      <td>7.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NES</th>\n",
       "      <td>128</td>\n",
       "      <td>The Legend of Zelda</td>\n",
       "      <td>1986.0</td>\n",
       "      <td>Action</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>3.74</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1.69</td>\n",
       "      <td>0.14</td>\n",
       "      <td>6.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NES</th>\n",
       "      <td>5864</td>\n",
       "      <td>Famista '91</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Namco Bandai Games</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NES</th>\n",
       "      <td>6163</td>\n",
       "      <td>Famista '92</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Namco Bandai Games</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NES</th>\n",
       "      <td>10311</td>\n",
       "      <td>Final Fantasy I &amp; II</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>Role-Playing</td>\n",
       "      <td>Square</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NES</th>\n",
       "      <td>11987</td>\n",
       "      <td>Teenage Mutant Ninja Turtles: Tournament Fighters</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>Fighting</td>\n",
       "      <td>Konami Digital Entertainment</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NES</th>\n",
       "      <td>12638</td>\n",
       "      <td>Adventures of Lolo</td>\n",
       "      <td>1989.0</td>\n",
       "      <td>Puzzle</td>\n",
       "      <td>HAL Laboratory</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>98 rows  10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Rank                                               Name    Year  \\\n",
       "Platform                                                                     \n",
       "NES           2                                  Super Mario Bros.  1985.0   \n",
       "NES          10                                          Duck Hunt  1984.0   \n",
       "NES          23                                Super Mario Bros. 3  1988.0   \n",
       "NES          97                                Super Mario Bros. 2  1988.0   \n",
       "NES         128                                The Legend of Zelda  1986.0   \n",
       "...         ...                                                ...     ...   \n",
       "NES        5864                                        Famista '91  1990.0   \n",
       "NES        6163                                        Famista '92  1991.0   \n",
       "NES       10311                               Final Fantasy I & II  1994.0   \n",
       "NES       11987  Teenage Mutant Ninja Turtles: Tournament Fighters  1992.0   \n",
       "NES       12638                                 Adventures of Lolo  1989.0   \n",
       "\n",
       "                 Genre                     Publisher  NA_Sales  EU_Sales  \\\n",
       "Platform                                                                   \n",
       "NES           Platform                      Nintendo     29.08      3.58   \n",
       "NES            Shooter                      Nintendo     26.93      0.63   \n",
       "NES           Platform                      Nintendo      9.54      3.44   \n",
       "NES           Platform                      Nintendo      5.39      1.18   \n",
       "NES             Action                      Nintendo      3.74      0.93   \n",
       "...                ...                           ...       ...       ...   \n",
       "NES             Sports            Namco Bandai Games      0.00      0.00   \n",
       "NES             Sports            Namco Bandai Games      0.00      0.00   \n",
       "NES       Role-Playing                        Square      0.00      0.00   \n",
       "NES           Fighting  Konami Digital Entertainment      0.04      0.01   \n",
       "NES             Puzzle                HAL Laboratory      0.06      0.00   \n",
       "\n",
       "          JP_Sales  Other_Sales  Global_Sales  \n",
       "Platform                                       \n",
       "NES           6.81         0.77         40.24  \n",
       "NES           0.28         0.47         28.31  \n",
       "NES           3.84         0.46         17.28  \n",
       "NES           0.70         0.19          7.46  \n",
       "NES           1.69         0.14          6.51  \n",
       "...            ...          ...           ...  \n",
       "NES           0.30         0.00          0.30  \n",
       "NES           0.28         0.00          0.28  \n",
       "NES           0.11         0.00          0.11  \n",
       "NES           0.02         0.00          0.07  \n",
       "NES           0.00         0.00          0.06  \n",
       "\n",
       "[98 rows x 10 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv.loc['NES']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "567d8ffb-6354-43bc-827b-081dde138ac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Platform\n",
       "PS2                       Grand Theft Auto: San Andreas\n",
       "PS2                         Grand Theft Auto: Vice City\n",
       "PS2                              Gran Turismo 3: A-Spec\n",
       "PS2                                Grand Theft Auto III\n",
       "PS2                                      Gran Turismo 4\n",
       "                             ...                       \n",
       "PS2        Sugar + Spice! Anoko no Suteki na Nanimokamo\n",
       "PS2                                      Kanokon: Esuii\n",
       "PS2                    Scarlett: Nichijou no Kyoukaisen\n",
       "PS2                                           Real Rode\n",
       "PS2    SCORE International Baja 1000: The Official Game\n",
       "Name: Name, Length: 2161, dtype: object"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv.loc['PS2','Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66e1e413-4918-4ab5-84b2-14f35edaac18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 3],\n",
       "       [5, 6]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "arr_a = np.array([[2,3],[5,6]])\n",
    "arr_a                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7f1190b0-5d31-4543-a395-3c1e9974bba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array is \n",
      " [[5 8]\n",
      " [0 2]]\n",
      " type is <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[90, 90],\n",
       "       [90, 90]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_a[0,1] #same as :\n",
    "arr_a[0][1] \n",
    "arr_a[1]\n",
    "# slicing \n",
    "arr_a[:,0]\n",
    "# negative indices - meaning traversing the array backwards\n",
    "arr_b = np.array([[4,7],[0,2]])\n",
    "arr_b[0,-1]\n",
    "# assigning values in numpy\n",
    "assert arr_b[0,-1] == 7\n",
    "arr_b[0,-1] = 9\n",
    "arr_b[0,:] = 100\n",
    "arr_b\n",
    "# we can also change entire vectors within an array\n",
    "\n",
    "# providing a list then accessing it :\n",
    "lst = [5,8]\n",
    "arr_b[0,:] = lst\n",
    "print(f\"Array is \\n {arr_b}\\n type is {type(arr_b)}\")\n",
    "# change the value of entire array to a single value :\n",
    "arr_b[:] = 90\n",
    "arr_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "37e6ea21-2309-42cd-a676-afdb340357ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array a :[7 3 9]\n",
      "array b: \n",
      "[[ 7  9  2]\n",
      " [ 5 11 -3]]\n",
      "list : [9, 0, 7, 2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([7, 3, 9])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# elementwise properties : same operation differs in list and arrays \n",
    "# creating 1d array :\n",
    "import numpy as np\n",
    "ar_a = np.array([6,2,8])\n",
    "# print(ar_a)\n",
    "\n",
    "# creating 2d array :\n",
    "ar_b = np.array([[5,7,0],[3,9,-5]])\n",
    "ar_a=ar_a + 1\n",
    "print(f\"array a :{ar_a}\")\n",
    "ar_b = ar_b + [2]\n",
    "print(f\"array b: \\n{ar_b}\")\n",
    "\n",
    "# but in list, '+' appends:\n",
    "lst = [9,0,7]\n",
    "lst = lst + [2]\n",
    "print(f\"list : {lst}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "376c0f74-aa8d-4462-b323-65dd650e5133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum [42 48 19]\n"
     ]
    }
   ],
   "source": [
    "# print(ar_a)\n",
    "ar_b\n",
    "ar_a =ar_a + ar_b[0]\n",
    "print(\"sum\",ar_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494cc628-0dd6-49d7-9d77-576abcf755e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also conduct operations between arrays of different dimensions - the shapes of the arrays need to be compatible ie length of 1d array must match length of 2d array \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1e9b9a9e-28ea-4399-9f21-9ad0d0126c90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6.        ,  5.33333333,  9.5       ],\n",
       "       [ 8.4       ,  4.36363636, -6.33333333]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar_a / ar_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "def858f6-0ca1-4fe6-91c7-081b03a3a6aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>signal_3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_vector</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             signal_3\n",
       "time_vector          \n",
       "0                 NaN\n",
       "1                 2.3\n",
       "2                 3.5\n",
       "3                 2.0\n",
       "5                 1.0"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np\n",
    "time_0 = [0, 1, 2, 3, 5]\n",
    "signal_3 = pd.Series([np.nan, 2.3, 3.5, 2.0, 1])\n",
    "\n",
    "expected_result_df = (\n",
    "            pd.DataFrame(\n",
    "                data={\n",
    "                    \"time_vector\": time_0,\n",
    "                    \"signal_3\": signal_3,\n",
    "                }\n",
    "            )\n",
    "            .set_index(\"time_vector\")\n",
    "            .sort_index(axis=0)\n",
    "        )\n",
    "expected_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc83b462-35c0-414d-9285-02acb5b7b370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2., 3., 4.],\n",
       "       [4., 5., 6.]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data supported by numpy:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "aa= np.array([[2,3,4],[4,5,6]],dtype=\"float32\") # 32bits of memory for each element of the array or can also use dtype= np.float16 to remove the quotes\n",
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d52b01e9-56c8-48ae-9a71-1e347c830cb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['20', '3', '4'],\n",
       "       ['4', '5', '6']], dtype='<U2')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "aa= np.array([[20,3,4],[4,5,6]],dtype=np.str_) # 32bits of memory for each element of the array or can also use dtype= np.float16 to remove the quotes\n",
    "aa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25a2597-17b3-4948-bb68-dc47942964d9",
   "metadata": {},
   "source": [
    "BROADCASTING : stretching one value over other to produce same size array. to perform operations with elements of diff size. , but arrays have to have the same shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "880f390f-d59b-4405-913b-67756cc8b141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6, 11, 16],\n",
       "       [13, 11, 11]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1 = np.array([4,5,7])\n",
    "a2 = np.array([[1],[3]])\n",
    "mc = np.array([[2,6,9],[9,6,4]])\n",
    "sum = np.add(a1,mc)\n",
    "sum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d006d57-01cc-439e-838c-775f1ae24bf4",
   "metadata": {},
   "source": [
    "TYPECASTING - taking every element of an arryay and changing it to specific datatype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d6ef2807-5860-4352-959e-54c30e34f8bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6., 11., 16.],\n",
       "       [13., 11., 11.]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum = np.add(a1,mc,dtype = np.float_)\n",
    "sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2399b8d-3088-457a-96c3-5ee238b0c634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.5 6.  6.5]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2, 6, 9],\n",
       "       [9, 6, 4]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# running a function over an axis. Axis 0 finds mean along the column, axis 1 finds mean along row.\n",
    "print(np.mean(mc, axis=0))\n",
    "mc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e782b366-6d7b-4718-ab42-682eca9ea5c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 6, 9],\n",
       "       [9, 6, 4]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "567b4f5b-1da6-4412-b868-7e8e0fd2a027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# working with arrays.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a072d83b-1085-41e7-ad8d-4acec8c68bd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    time_step = 0.1\n",
    "    end_time = 25\n",
    "    length = round(end_time/time_step)\n",
    "    length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ad67bab5-01ed-45e3-98cb-a35867656c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "    t = np.zeros(length)\n",
    "    stp = np.zeros(length)\n",
    "    v = np.zeros(length)\n",
    "    command = np.zeros(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5a1d1acb-ca51-4dbd-8516-13d3ff03899a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01515ae-f95e-42ff-8b5c-349d10adc35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade jupyterhub\n",
    "\n",
    "# pip install --upgrade --user nbconvert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "b773db00-85b1-4d8b-ba37-7786a2395b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# another datatype is ndarray in python - can store multiple values in sequence, elementwise operation. originates from numpy package. helps in computation. n stands for natural numbers, d can be any number like 1,2,3\n",
    "# 1d of size 3\n",
    "import numpy as np\n",
    "a1 = np.array([1,2,3])\n",
    "type(a1)\n",
    "a1.shape\n",
    "\n",
    "a2 = np.array([[4,5,6],[7,8,9]])\n",
    "a2.shape\n",
    "type(a2)\n",
    "a2.shape[1] # FOR 0 IT'S ROWS, 1 GIVES NUMBER OF COLS.\n",
    "\n",
    "a3 = np.array(2)\n",
    "type(a3)\n",
    "print(a3)\n",
    "a3.shape # retrieves void means arr3 has no shape or size - that's because we have to specify within []."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "f6d7c9f3-b8c5-4c44-b5fc-86468cbe540c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "<class 'list'>\n",
      "<class 'numpy.ndarray'>\n",
      "l1 : [[3, 5, 6], [7, 8, 3]]\n",
      "array :  [[3 5 6]\n",
      " [7 8 3]]\n"
     ]
    }
   ],
   "source": [
    "# arrays vs lists : array operations work element wise while list operations dont.\n",
    "\n",
    "l1 = [[3,5,6],[7,8,3]]\n",
    "print(len(l1))\n",
    "print(type(l1))\n",
    "aa1 = np.array(l1,dtype = object)\n",
    "print(type(aa1))\n",
    "\n",
    "print(f\"l1 : {l1}\")\n",
    "print(\"array : \",aa1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "8cb60cd0-3504-49e3-91e1-d4e89894b9b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa1.shape\n",
    "len(aa1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "649dedf5-151e-49f7-a9f5-6f946b61279b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(l1[1]) #can access the list and array elements this way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "97bf7dd4-f74b-4a73-8993-2ab9f3316d7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 5, 6, 7, 8, 3]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_list = l1[0] + l1[1]\n",
    "sum_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "052a622d-aea2-4439-a4ad-7a38b3156c83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10, 13, 9], dtype=object)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_list = aa1[0] + aa1[1] #is summed with each element in each column\n",
    "array_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "68632393-63d4-4bea-8587-b08829bc8462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.6457513110645907"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# follwing operatoin can be done in the arrays and not in lists\n",
    "import math\n",
    "sqrti = math.sqrt(aa1[1,0])\n",
    "sqrti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "924791a9-3ac6-4e61-ae53-d8ad0714b61a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   -1    -1    -1 ...    -1    -1    -1]\n",
      " [    1    -1    -1 ...    -1    -1 16600]\n",
      " [    2    -1    -1 ...    -1    -1 16600]\n",
      " ...\n",
      " [ 1041    -1    -1 ...    -1    -1 16600]\n",
      " [ 1042    -1    -1 ...    -1    -1 15600]\n",
      " [ 1043    -1    -1 ...    -1    -1 16600]]\n"
     ]
    }
   ],
   "source": [
    "# string vs object vs numbers\n",
    "# using the genrate from text function\n",
    "import numpy as np\n",
    "lend = np.genfromtxt(\"lending-co-LT.csv\",delimiter = ',',dtype = np.int_)#this func is more stable than np.loadtxt() ; to import the datatypes as integers, use dtype\n",
    "print(lend) #using print func will eliminate word array from the output\n",
    "# arrays use only single data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "9fbc35de-b365-4f14-9a60-0498a62b5184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(lend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24b59d4a-683d-4dfa-8260-0b128acf5a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matd : \n",
      "[[7 8 9 0 1]\n",
      " [1 4 7 0 3]\n",
      " [4 3 7 1 2]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# slicing in numpy - slicers are smaller arrays\n",
    "import numpy as np\n",
    "mat = np.array([[1,2,3],[5,6,7]])\n",
    "mat\n",
    "# basic slicing \n",
    "mat[1:2] #both indices refer to rows, unless it's separated by comma => in which case it refers to row and column\n",
    "mat[2:]\n",
    "mat[:,-1]\n",
    "mat[1:,:1]\n",
    "# step-wise slicing eg - mat[1(start):10(end):3(step),2:11:3] , by default step is set to 1\n",
    "matb = np.array([[7,3,9,5,6],[2,4,1,9,8],[9,7,8,1,2]])\n",
    "# print(f\"matb:\\n {matb}\")\n",
    "matb[0:2,-3]\n",
    "matb[-1::-2,::3]\n",
    "# conditional slicing  \n",
    "matc = np.array([[7,3,9,5,6],[2,4,1,9,8],[9,7,8,1,2]])\n",
    "# print(f\"matc:\\n{matc}\")\n",
    "matc[0:2:,1:2:] #slicing the first column\n",
    "matc[:,0] > 2 #array filled with true and false values (each val in first col of matc is checked against the condition)\n",
    "# to print all values in matc greater than 2 :\n",
    "matc[matc[:,:]<20]\n",
    "# additional multiple conditions using the &,| symbol:\n",
    "matc[(matc[:,:] > 2) & (matc[:,:] ==4)]\n",
    "\n",
    "# dimensions and sqeeze function : the sqeeze method gets rid of unwanted dimensions\n",
    "matd = np.array([[7,8,9,0,1],[1,4,7,0,3],[4,3,7,1,2]])\n",
    "print(f\"matd : \\n{matd}\")\n",
    "type(matd[0,0]) #python recognises this as a single numeric value\n",
    "matd[0,0:1] \n",
    "# to sqeeze :\n",
    "matd[0,0:1].squeeze().shape #sqeezed array has no shape making it a 0-D array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6f2fcd6e-227e-4071-901d-b0dbebc25602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 1  2  3  4  5]\n",
      "  [11 21 31 41 51]]\n",
      "\n",
      " [[11 12 13 14 15]\n",
      "  [51 52 53 54  5]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_2D = np.array([[20,30,40,50,60], [43,54,65,76,87], [11,22,33,44,55]])\n",
    "array_2D\n",
    "array_2D[:,0]\n",
    "array_3D = np.array([[[1,2,3,4,5], [11,21,31,41,51]], [[11,12,13,14,15], [51,52,53,54,5]]])\n",
    "print(array_3D)\n",
    "array_3D[0:1:1]\n",
    "array_3D[ :,  0::2]\n",
    "array_3D[0]\n",
    "# The syntax for the indices of the 3-D array is the following: [subarray, row, column])--------------\n",
    "array_3D[:, :, 0::2 ]\n",
    "\n",
    "# Use conditional slicing to check if the individual elements of each array satisfy a given condition (e.g. greater than 10)\n",
    "array_3D> 10\n",
    "#  to print those values\n",
    "array_3D[array_3D > 10]\n",
    "\n",
    "# Odd numbers leave a remainder of 1, when dividing by 2. Hence, we can use \"%\" to express this condition.)\n",
    "array_3D[(array_3D > 10) | (array_3D %2 != 0)] \n",
    "np.squeeze(array_3D[ :1, 0:1   ]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf3f9af-6028-4173-8eb5-7e8fb35cf64d",
   "metadata": {},
   "source": [
    "generating data with numpy : \n",
    "arrays of 0s and 1s\n",
    "some functions that randomly generate arrays of data are : np.empty() ; np.zeros() ; np.ones() ; np.full()\n",
    "disadvantage of using these functions is that they dont produce consistent numbers or outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3ade79c9-a7ab-43a0-9ecd-17ba5657867e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.2840585 , -0.940852  , -0.05083524, -0.0247315 , -0.07595215],\n",
       "       [-0.71238607, -0.98467683, -0.77736035,  0.23645487, -0.29017916],\n",
       "       [-0.70690253, -0.8432795 ,  0.72151318,  0.0889527 ,  0.68379081],\n",
       "       [ 0.26420243, -1.74358139,  0.08291143,  0.43035477,  0.31427208],\n",
       "       [ 0.39591195, -0.04692129, -0.98192506, -1.93099719,  0.80199798]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "gen_1 = np.empty(shape=(2,3))\n",
    "gen_1\n",
    "gen_2 = np.zeros(shape=(3,4)) #shows float\n",
    "gen_2\n",
    "gen_2 = np.zeros(shape=(3,4),dtype=np.int8) #in int\n",
    "gen_2\n",
    "gen_3 = np.ones(shape = (2,3))\n",
    "gen_3\n",
    "gen_4 = np.full(shape = (2,3), fill_value=\"twenty four\")\n",
    "gen_4\n",
    "# like functions in numpy:\n",
    "gen_1 = np.empty_like(gen_1)\n",
    "gen_1\n",
    "\n",
    "#arange() function enerates an array of consecutive values. - non-random sequence of numbers\n",
    "rng = np.arange(23,56,4)\n",
    "rng\n",
    "lst = list(range(10))\n",
    "lst\n",
    "\n",
    "# random generators and seeds\n",
    "from numpy.random import Generator as gen\n",
    "from numpy.random import PCG64 as pcg\n",
    "rand_seed = gen(pcg())\n",
    "rand_seed.normal(size = (5,5))\n",
    "\n",
    "rand_seed = gen(pcg(seed = 300))\n",
    "rand_seed.normal(size = (5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0de72fe4-82bf-45aa-a2fc-9484b4d1c4d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1.],\n",
       "       [1., 1., 1.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# probability distribution in numpy like poison and binomial distro - ( in a fixed interval of time we expect an event to occur once - can be set with lam)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0beb41-a420-413b-bc10-943979950710",
   "metadata": {},
   "source": [
    "APPS OF RANDOM GENERATORS :\n",
    "When real data isn't available , we sometimes need pseudo-random data to test how well a program performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49380e17-75a1-4ec1-a069-74233eb50d3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from numpy.random import Generator as gen\n",
    "from numpy.random import PCG64 as pcg\n",
    "rg = gen(pcg(seed = 365))\n",
    "\n",
    "ac1 = rg.normal(loc = 2, scale = 3, size = (1000))\n",
    "ac2 = rg.normal(loc = 7, scale = 2, size = (1000))\n",
    "ac3 = rg.logistic(loc = 11, scale = 3, size = (1000))\n",
    "ac4 = rg.exponential(scale = 4, size = (1000))\n",
    "ac5 = rg.geometric(p = 0.7, size = (1000))\n",
    "\n",
    "# create np array function to hold all data\n",
    "test_data = np.array([ac1,ac2,ac3,ac4,ac5])\n",
    "test_data.transpose().shape\n",
    "# test_data.shape\n",
    "\n",
    "# exporting this array into a cvs file - (syntax using the savetxt function is - name, dataset, format)\n",
    "np.savetxt(\"Data_from_rand_gen.csv\", test_data, fmt= \"%s\", delimiter= ',')\n",
    "\n",
    "# importing above - using genfromtxt function\n",
    "np.genfromtxt(\"Data_from_rand_gen.csv\", delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ee1fb32a-17a7-42d5-806c-70591ebedfe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m: \n",
      "[[20 30 40 50 60]\n",
      " [43 54 65 76 87]\n",
      " [11 22 33 44 55]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[250. , 275. , 275. ],\n",
       "       [275. , 302.5, 302.5],\n",
       "       [275. , 302.5, 302.5]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# statistical functions in numpy\n",
    "# mean()\n",
    "m = np.array([[20,30,40,50,60], [43,54,65,76,87], [11,22,33,44,55]])\n",
    "print(f\"m: \\n{m}\")\n",
    "np.mean(m[0])\n",
    "m.mean()\n",
    "#min and max()\n",
    "np.max(m)\n",
    "np.min(m[1])\n",
    "# amin - working with arrays, serve same purpose as min()\n",
    "np.amin(m[0])\n",
    "# minimum function takes 2 input arrays and performs element wise \n",
    "np.minimum(m[0],m[2])\n",
    "# percentiles and quantiles\n",
    "# peak to peak + along an axis- returns rhe difference b/w highest and lowest value within an array\n",
    "np.ptp(m,axis=0)\n",
    "#percentile - returns the percentile of a specific set\n",
    "np.sort(m, axis=None)\n",
    "np.percentile(m, 1)\n",
    "# median is the middle value of the sorted dataset \n",
    "# /quantile\n",
    "np.quantile(m,0.70,interpolation=\"nearest\")\n",
    "# avergaes and variances:\n",
    "np.sort(m,axis=None)\n",
    "np.median(m)\n",
    "np.average(m)\n",
    "np.mean(m)\n",
    "np.var(m) #variance\n",
    "# std - standard deviation\n",
    "np.std(m)\n",
    "# covariance and correlation\n",
    "np.cov(m)\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "412da5c7-5fc9-4300-84fe-f900519a6bbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# histograms in numpy \n",
    "# NAN equivalent functions - functions that work on arrays with missing values in them; they are very useful when working with incomplete data\n",
    "import numpy as np\n",
    "matrix_A = np.array([[1,2,3,4,5],[5,6,7,8,9],[9,10,11,12,13]])\n",
    "matrix_A\n",
    "np.nanmean(matrix_A)\n",
    "matrix_B = np.array([[1,2,3,4,5],[5,6,np.nan,8,9],[9,10,11,12,13]])\n",
    "np.nanmean(matrix_B)\n",
    "# np.mean(matrix_B) - this does not return an identical result as before nanmean when facing incomplete data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30f96c6-2cf4-4240-8c8b-20a71fd20758",
   "metadata": {},
   "source": [
    "#################### Data Manipulation ###################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "39fecadb-089d-46d8-9f5a-5545e33dc633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "# one of the ways to check for missing values in a dateset is to use the loadtxt() function. Unlike genfromtxt() this function not only imports the data but outputs the missing values when we try to call a text file\n",
    "data_numeric = np.loadtxt(\"C:\\\\Users\\\\TJO1COB\\\\Downloads\\\\Lending-company-Numeric.csv\", delimiter = ',')\n",
    "data_numeric\n",
    "# to check for missing values\n",
    "np.isnan(data_numeric).sum() # will return 0 if there is no missing value or a value of how many missing data is present\n",
    "\n",
    "data_numeric_nan = np.loadtxt(\"C:\\\\Users\\\\TJO1COB\\\\Downloads\\\\Lending-company-Numeric-NAN.csv\", delimiter = ';')\n",
    "data_numeric_nan # weget a value error because the method reads the missing data as empty spaces hence loadtxt crashes.\n",
    "# hence switch to numpy func genfromtext() to import text files\n",
    "data_numeric_nan1 = np.genfromtxt(\"C:\\\\Users\\\\TJO1COB\\\\Downloads\\\\Lending-company-Numeric-NAN.csv\", delimiter = ';')\n",
    "np.isnan(data_numeric_nan1).sum()\n",
    "\n",
    "# filling values: filled every empty value with 0. - not a great approach, good apprach is to fill with max or mean values\n",
    "temp_fill = np.nanmax(data_numeric_nan1).round(2) + 1\n",
    "temp_fill\n",
    "data_numeric_nan1 = np.genfromtxt(\"C:\\\\Users\\\\TJO1COB\\\\Downloads\\\\Lending-company-Numeric-NAN.csv\", delimiter = ';', filling_values = temp_fill)\n",
    "np.isnan(data_numeric_nan1).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "210da330-e7c6-4ccb-b64d-9b49023b1965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2250.25"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# substituting values\n",
    "data_numeric_nan = np.genfromtxt(\"C:\\\\Users\\\\TJO1COB\\\\Downloads\\\\Lending-company-Numeric-NAN.csv\", delimiter = ';')\n",
    "data_numeric_nan\n",
    "temp_mean = np.nanmean(data_numeric_nan, axis=0).round(2)\n",
    "temp_mean[0]\n",
    "# choosing a filler value\n",
    "temp_fill_max = np.nanmax(data_numeric_nan1).round(2) + 1\n",
    "temp_fill_max #substituting every empty value with this one \n",
    "lend_data = np.genfromtxt(\"C:\\\\Users\\\\TJO1COB\\\\Downloads\\\\Lending-company-Numeric-NAN.csv\", delimiter = ';', filling_values=temp_fill_max)\n",
    "lend_data\n",
    "# finding mean of first column in nan dataset:\n",
    "np.mean(lend_data[:,0]).round(2)\n",
    "temp_mean[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0ad90028-bc23-4298-b065-fb40da1d8893",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 2000.,    40.,   365., ...,   365.,  1581.,  3041.],\n",
       "        [12277.,  2000.,    40., ...,    50.,   365.,  5350.],\n",
       "        [ 6850., 15150.,  1000., ...,  2000.,    40.,   365.]],\n",
       "\n",
       "       [[ 3101.,  4351., 16600., ..., 16600.,  2000.,    40.],\n",
       "        [  365.,  3441.,  4661., ...,  8450., 22250.,  2000.],\n",
       "        [   40.,   365.,  3701., ...,  4601.,  4601., 16600.]]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshaping nd arrays\n",
    "import numpy as np\n",
    "lend_num = np.loadtxt(\"C:\\\\Users\\\\TJO1COB\\\\Downloads\\\\Lending-company-Numeric.csv\", delimiter = ',')\n",
    "lend_num.shape\n",
    "np.reshape(lend_num, (6,1043))\n",
    "np.transpose(lend_num)\n",
    "# np.reshape(lend_num, (3,500)) #outputs error because it cant contain all 6258 elements inside the array meaning the product should equal 6258 => hence it can be reshaped to (5,\n",
    "np.reshape(lend_num, (2,3,1043))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c6d3710f-1317-4488-aed2-78fe389e4911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "org :\n",
      " [[ 2000.    40.   365.  3121.  4241. 13621.]\n",
      " [ 2000.    40.   365.  3061.  4171. 15041.]\n",
      " [ 1000.    40.   365.  2160.  3280. 15340.]\n",
      " ...\n",
      " [ 2000.    40.   365.  4201.  5001. 16600.]\n",
      " [ 1000.    40.   365.  2080.  3320. 15600.]\n",
      " [ 2000.    40.   365.  4601.  4601. 16600.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 2000.,    40.,   365.,  3121.,  4241., 13621.],\n",
       "       [ 2000.,    40.,   365.,  3041.,  4241., 15321.],\n",
       "       [ 2000.,    50.,   365.,  3470.,  4820., 13720.],\n",
       "       ...,\n",
       "       [ 2000.,    40.,   365.,  4201.,  5001., 16600.],\n",
       "       [ 1000.,    40.,   365.,  2080.,  3320., 15600.],\n",
       "       [ 2000.,    40.,   365.,  4601.,  4601., 16600.]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove values from an array\n",
    "lend_num = np.loadtxt(\"C:\\\\Users\\\\TJO1COB\\\\Downloads\\\\Lending-company-Numeric.csv\", delimiter = ',')\n",
    "print(f\"org :\\n {lend_num}\")\n",
    "# np.delete(lend_num,2)\n",
    "# get rid of entire rows and columns\n",
    "np.delete(lend_num,(2,1,2),axis=0) # removes first row of matrix syntax - array, individual index row/col number, axis argument 0 or 1 indicates its row or col respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "30b33020-7835-4646-8f1f-590ab65da0a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "org : \n",
      " [[ 2000.    40.   365.  3121.  4241. 13621.]\n",
      " [ 2000.    40.   365.  3061.  4171. 15041.]\n",
      " [ 1000.    40.   365.  2160.  3280. 15340.]\n",
      " ...\n",
      " [ 2000.    40.   365.  4201.  5001. 16600.]\n",
      " [ 1000.    40.   365.  2080.  3320. 15600.]\n",
      " [ 2000.    40.   365.  4601.  4601. 16600.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1000.,    35.,   365., -2870., -2870.,  -350.],\n",
       "       [ 1000.,    35.,   365., -2550., -2100.,   150.],\n",
       "       [ 1000.,    35.,   365., -2450., -2000.,  1100.],\n",
       "       ...,\n",
       "       [ 9000.,   125.,   365., 16751., 18751., 54625.],\n",
       "       [ 9000.,   165.,   365., 17650., 20001., 54625.],\n",
       "       [ 9000.,   165.,   365., 19001., 22001., 64001.]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sorting N-D arrays - returns sorted array in ascending order\n",
    "lend_num = np.loadtxt(\"C:\\\\Users\\\\TJO1COB\\\\Downloads\\\\Lending-company-Numeric.csv\", delimiter = ',')\n",
    "print(f\"org : \\n {lend_num}\")\n",
    "np.set_printoptions(suppress=True)\n",
    "np.sort(lend_num,axis=None) #(in increasing order)\n",
    "np.sort(-lend_num) #turns positive values to negative)\n",
    "-np.sort(-lend_num) # values are placed from largest to smallest\n",
    "lend_num[:,3].sort() #rearranage value of just one col \n",
    "lend_num\n",
    "lend_num.sort(axis=0) #to overwrite entire dataset, remove index and add axis value.\n",
    "lend_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfe419a-ef22-4acc-9351-d5d2b2718b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# argument sort in numpy\n",
    "import numpy as np\n",
    "data1 = np.loadtxt(\"C:\\\\Users\\\\TJO1COB\\\\Downloads\\\\Lending-company-Numeric.csv\", delimiter = ',')\n",
    "# print(f\"org : \\n {data1}\")\n",
    "data1.shape\n",
    "data1.size #size is the product of elements of shape\n",
    "np.argsort(data1) # result is an array that consists of numbers from 0 to 5(in this case), this is because instead of sorting the value themselves, the function returns the indices of the array.\n",
    "np.sort(data1)\n",
    "# can call the function over a given axis :\n",
    "np.argsort(data1, axis=0) #0 corresponds to col\n",
    "data1[482,5]\n",
    "# arrange the first cols and get their indices\n",
    "np.argsort(data1[0,:])\n",
    "data1 = data1[np.argsort(data1[:,0])]\n",
    "data1\n",
    "# argument where in numpy\n",
    "np.argwhere(data1) # output syntax = [row index, col index]; argument where function goes over the entire NDarray and checks whether individual elements satisfy a given condition; default condt is to check for values different from 0\n",
    "#  to check where zeroes appear in the array, set the condition equals false\n",
    "np.argwhere(data1== False)\n",
    "# for other conditions :\n",
    "np.argwhere(data1 % 2 ==0)\n",
    "#  to check based on above output:\n",
    "data1[219,   4]\n",
    "\n",
    "# to load the data from nan csv\n",
    "data1_nan = np.genfromtxt(\"C:\\\\Users\\\\TJO1COB\\\\Downloads\\\\Lending-company-Numeric-NAN.csv\", delimiter = ';')\n",
    "# print(f\"nan_array : \\n {data1_nan}\")\n",
    "np.argsort(data1_nan)\n",
    "np.argwhere(data1_nan)\n",
    "np.argwhere(np.isnan(data1_nan)) #this returns the indices of all values that contains nan values\n",
    "# data1_nan[11,3] # to check based on above output.\n",
    "for array_index in np.argwhere(np.isnan(data1_nan)):\n",
    "    # print(array_index)\n",
    "    data1_nan[array_index[0], array_index[1]] = 0 #substituting the values of nan by 0 by accessing the array indexes of those returned\n",
    "data1_nan [175]\n",
    "np.isnan(data1_nan).sum() #if sum is returned as 0, there are no missing values present in the array.\n",
    "\n",
    "# applying shuffling to NDarrays: we can't replicate the same shuffle twice\n",
    "# to load only the first 8 rows of dataset :\n",
    "lend_8 = np.loadtxt(\"C:\\\\Users\\\\TJO1COB\\\\Downloads\\\\Lending-company-Numeric.csv\",delimiter=',')[:8]\n",
    "# print(f\"org : \\n {lend_8}\")\n",
    "np.random.shuffle(lend_8)\n",
    "lend_8\n",
    "\n",
    "lend = np.loadtxt(\"C:\\\\Users\\\\TJO1COB\\\\Downloads\\\\Lending-company-Numeric.csv\",delimiter=',')\n",
    "lend\n",
    "from numpy.random import shuffle\n",
    "shuffle(lend)\n",
    "lend\n",
    "from numpy.random import Generator as gen\n",
    "from numpy.random import PCG64 as pcg\n",
    "array_RG = gen(pcg(seed=365))\n",
    "array_RG.shuffle(lend)\n",
    "lend\n",
    "\n",
    "# switch datatypes using casting : typecasting - taking an object with values of a certain dtype and creating an identical object that contains value of diff dtype\n",
    "lend = np.loadtxt(\"C:\\\\Users\\\\TJO1COB\\\\Downloads\\\\Lending-company-Numeric.csv\",delimiter=',')\n",
    "lend.astype(dtype = np.int16)\n",
    "# creating an array of strings by casting the array containing integer\n",
    "lend.astype(dtype = np.str)\n",
    "lend\n",
    "\n",
    "lend=lend.astype(dtype = str)\n",
    "lend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d4306089-5ff5-465c-a151-3134b1e4ae57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   40.,    50.,   365.,  1000.,  2000.,  2160.,  3041.,  3061.,\n",
       "        3121.,  3280.,  3470.,  4171.,  4241.,  4820., 13621., 13720.,\n",
       "       15041., 15321., 15340.])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concatenating in numpy arrays\n",
    "lend = np.loadtxt(\"C:\\\\Users\\\\TJO1COB\\\\Downloads\\\\Lending-company-Numeric.csv\",delimiter=',')\n",
    "np.concatenate((lend[0,:],lend[1,:])) #resultant is a 1D array\n",
    "\n",
    "# finding unique values in NDarrays - the unique functions takes an array as input and creates another array that contains all the different values from the first one.\n",
    "lend = np.loadtxt(\"C:\\\\Users\\\\TJO1COB\\\\Downloads\\\\Lending-company-Numeric.csv\",delimiter=',')\n",
    "np.unique(lend[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc20edc4-3973-48b4-a32f-0a2f2dc68ad0",
   "metadata": {},
   "source": [
    "########### RAW DATA SET CLEANING AND PROCESSING ##############\n",
    "# gathering, cleaning and preprocessing then construct predictive models\n",
    "<!-- note down all valuable changes to the original dataset -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e380d829-766a-4cbd-bcf6-659b03a3f888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the loan data and examine the contents - this file uses ; as delimiter hence has it to be kept in mind while importing\n",
    "\n",
    "# import packages\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b53f3fc9-c2ab-4b8f-86d6-d60f93bb55ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' for easier viewwing let's also call the print set option function - improve the way we see the output, the below given arguments will stop numpy from using scientific notations to express numbers\n",
    "extend no of char we fit in single line output to 100  ; only display the first 2 digits after decimal point using precision argument. specifying these args wont alter the numerical values that numpy uses for math operations.\n",
    "it only affects how we see values on screen.'''\n",
    "np.set_printoptions(suppress=True, linewidth=100, precision=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f51a9dd-4e07-4189-9a9d-90dd2ca36dc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[        nan,         nan,         nan, ...,         nan,         nan,         nan],\n",
       "       [48010226.  ,         nan,    35000.  , ...,         nan,         nan,     9452.96],\n",
       "       [57693261.  ,         nan,    30000.  , ...,         nan,         nan,     4679.7 ],\n",
       "       ...,\n",
       "       [50415990.  ,         nan,    10000.  , ...,         nan,         nan,     2185.64],\n",
       "       [46154151.  ,         nan,         nan, ...,         nan,         nan,     3199.4 ],\n",
       "       [66055249.  ,         nan,    10000.  , ...,         nan,         nan,      301.9 ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using loadtxt as it returns error message since there is missing data \"ValueError: could not convert string to float: 'id'\" is thrown, hence switch to genfromtxt\n",
    "# raw_data = np.loadtxt(\"C:\\\\Users\\\\TJO1COB\\\\Downloads\\\\loan-data.csv\", delimiter=';')\n",
    "raw_data = np.genfromtxt(\"C:\\\\Users\\\\TJO1COB\\\\Downloads\\\\loan-data.csv\", delimiter=';')\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a938309-fee9-4a4b-8f01-e1582a9bfbe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[48010226.  ,         nan,    35000.  , ...,         nan,         nan,     9452.96],\n",
       "       [57693261.  ,         nan,    30000.  , ...,         nan,         nan,     4679.7 ],\n",
       "       [59432726.  ,         nan,    15000.  , ...,         nan,         nan,     1969.83],\n",
       "       ...,\n",
       "       [50415990.  ,         nan,    10000.  , ...,         nan,         nan,     2185.64],\n",
       "       [46154151.  ,         nan,         nan, ...,         nan,         nan,     3199.4 ],\n",
       "       [66055249.  ,         nan,    10000.  , ...,         nan,         nan,      301.9 ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use skip_header to omit nan values ; setting autostrip to True as it removes excess whitespace that distorts the data\n",
    "raw_data = np.genfromtxt(\"C:\\\\Users\\\\TJO1COB\\\\Downloads\\\\loan-data.csv\", delimiter=';', skip_header=1, autostrip=True)\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e660d960-c405-4744-8fbf-08c430c70e9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88005"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examining the missing elements - check for incomplete data and using the method chaining sum at the end - returns false (0) if there are no missing values, hence we check if sum=0, else number of missing elements is retrieved\n",
    "np.isnan(raw_data).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c7a9a12-b3c0-4aec-97a1-1717956a83e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TJO1COB\\AppData\\Local\\Temp\\ipykernel_15020\\3806063239.py:5: RuntimeWarning: Mean of empty slice\n",
      "  temp_mean = np.nanmean(raw_data, axis=0)\n"
     ]
    }
   ],
   "source": [
    "# tackling above\n",
    "# this stores the rounded result of nanmax + 1 ; serves as filler for all missing entries in dataset\n",
    "temp_fill = np.nanmax(raw_data) + 1\n",
    "# output of nanmean ran over axis; holds the means for every cols\n",
    "temp_mean = np.nanmean(raw_data, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54a25dfd-a632-4767-90d6-c8f21b45387c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([54015809.19,         nan,    15273.46,         nan,    15311.04,         nan,       16.62,\n",
       "            440.92,         nan,         nan,         nan,         nan,         nan,     3143.85])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to determine how many cols exactly contain of text values\n",
    "temp_mean \n",
    "# contains 8 cols as nan "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf810b85-0cac-4e5a-bf2c-e835909e5690",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TJO1COB\\AppData\\Local\\Temp\\ipykernel_15020\\2074903938.py:2: RuntimeWarning: All-NaN slice encountered\n",
      "  temp_stats = np.array([np.nanmin(raw_data, axis = 0), temp_mean, np.nanmax(raw_data, axis = 0)])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  373332.  ,         nan,     1000.  ,         nan,     1000.  ,         nan,        6.  ,\n",
       "              31.42,         nan,         nan,         nan,         nan,         nan,        0.  ],\n",
       "       [54015809.19,         nan,    15273.46,         nan,    15311.04,         nan,       16.62,\n",
       "             440.92,         nan,         nan,         nan,         nan,         nan,     3143.85],\n",
       "       [68616519.  ,         nan,    35000.  ,         nan,    35000.  ,         nan,       28.99,\n",
       "            1372.97,         nan,         nan,         nan,         nan,         nan,    41913.62]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create array using nanmin, max\n",
    "temp_stats = np.array([np.nanmin(raw_data, axis = 0), temp_mean, np.nanmax(raw_data, axis = 0)])\n",
    "temp_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c594b577-a188-4b22-8f9d-0a64af9e07d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  3,  5,  8,  9, 10, 11, 12], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''splitting the data into 2 smaller arrays - one for handling numeric data and one for string vals. info on which col is string and numeric can be inferred from the previous output from mean'''\n",
    "# use argwhere function, to find the indices of cols that are string, default conditions fro argwhere tests whether the values ! = 0\n",
    "col_strings=np.argwhere(np.isnan(temp_mean)).squeeze()\n",
    "col_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dacff3b0-2a09-4c95-9cfc-d667dcaddce4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  2,  4,  6,  7, 13], dtype=int64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to check which cols contain numeric values\n",
    "col_num=np.argwhere(np.isnan(temp_mean)== False).squeeze()\n",
    "col_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1c70ee60-f98e-4bcf-a3ad-e4614b196003",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TJO1COB\\AppData\\Local\\Temp\\ipykernel_15020\\726611971.py:5: DeprecationWarning: `np.str` is a deprecated alias for the builtin `str`. To silence this warning, use `str` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.str_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  autostrip=True, usecols=col_strings, dtype = np.str\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([['May-15', 'Current', '36 months', ..., 'Verified',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=48010226', 'CA'],\n",
       "       ['', 'Current', '36 months', ..., 'Source Verified',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=57693261', 'NY'],\n",
       "       ['Sep-15', 'Current', '36 months', ..., 'Verified',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=59432726', 'PA'],\n",
       "       ...,\n",
       "       ['Jun-15', 'Current', '36 months', ..., 'Source Verified',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=50415990', 'CA'],\n",
       "       ['Apr-15', 'Current', '36 months', ..., 'Source Verified',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=46154151', 'OH'],\n",
       "       ['Dec-15', 'Current', '36 months', ..., '',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=66055249', 'IL']],\n",
       "      dtype='<U69')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reimporting dataset with string data\n",
    "loan_data_strings = np.genfromtxt(\"C:\\\\Users\\\\TJO1COB\\\\Downloads\\\\loan-data.csv\", \n",
    "                         delimiter=';',\n",
    "                         skip_header=1, \n",
    "                         autostrip=True, usecols=col_strings, dtype = np.str\n",
    "            )\n",
    "loan_data_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "faf428c8-8bea-4eb1-8a36-fb8f4c676c22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[48010226.  ,    35000.  ,    35000.  ,       13.33,     1184.86,     9452.96],\n",
       "       [57693261.  ,    30000.  ,    30000.  , 68616520.  ,      938.57,     4679.7 ],\n",
       "       [59432726.  ,    15000.  ,    15000.  , 68616520.  ,      494.86,     1969.83],\n",
       "       ...,\n",
       "       [50415990.  ,    10000.  ,    10000.  , 68616520.  , 68616520.  ,     2185.64],\n",
       "       [46154151.  , 68616520.  ,    10000.  ,       16.55,      354.3 ,     3199.4 ],\n",
       "       [66055249.  ,    10000.  ,    10000.  , 68616520.  ,      309.97,      301.9 ]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reimporting dataset with numeric data\n",
    "loan_data_numeric = np.genfromtxt(\"C:\\\\Users\\\\TJO1COB\\\\Downloads\\\\loan-data.csv\", \n",
    "                         delimiter=';',\n",
    "                         skip_header=1, \n",
    "                         autostrip=True, usecols=col_num, filling_values=temp_fill\n",
    "            )\n",
    "loan_data_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "676ec0e6-d9e3-4f43-977a-bcc6cc173a3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[48010226.  ,         nan,    35000.  , ...,         nan,         nan,     9452.96],\n",
       "       [57693261.  ,         nan,    30000.  , ...,         nan,         nan,     4679.7 ],\n",
       "       [59432726.  ,         nan,    15000.  , ...,         nan,         nan,     1969.83],\n",
       "       ...,\n",
       "       [50415990.  ,         nan,    10000.  , ...,         nan,         nan,     2185.64],\n",
       "       [46154151.  ,         nan,         nan, ...,         nan,         nan,     3199.4 ],\n",
       "       [66055249.  ,         nan,    10000.  , ...,         nan,         nan,      301.9 ]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data_np = np.genfromtxt(\"C:\\\\Users\\\\TJO1COB\\\\Downloads\\\\loan-data.csv\", \n",
    "                         delimiter=';',\n",
    "                         skip_header=1, \n",
    "                         autostrip=True\n",
    "            )\n",
    "raw_data_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5ac6bc62-2b0d-4544-9311-96befabeab29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'issue_d', 'loan_amnt', 'loan_status', 'funded_amnt', 'term', 'int_rate',\n",
       "       'installment', 'grade', 'sub_grade', 'verification_status', 'url', 'addr_state',\n",
       "       'total_pymnt'], dtype='<U19')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# names of cols\n",
    "header_full = np.genfromtxt(\"C:\\\\Users\\\\TJO1COB\\\\Downloads\\\\loan-data.csv\", \n",
    "                         delimiter=';',\n",
    "                         autostrip=True,\n",
    "                         skip_footer = raw_data_np.shape[0], \n",
    "                         dtype = np.str_\n",
    "            )\n",
    "header_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6c49f44c-f0d7-47af-8d17-31f262e941e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['id', 'loan_amnt', 'funded_amnt', 'int_rate', 'installment', 'total_pymnt'], dtype='<U19'),\n",
       " array(['issue_d', 'loan_status', 'term', 'grade', 'sub_grade', 'verification_status', 'url',\n",
       "        'addr_state'], dtype='<U19'))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# splitting the above headers into 2 variables\n",
    "header_string, header_numeric = header_full[col_strings],header_full[col_num]\n",
    "header_numeric,header_string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5298e9-8c97-4f02-80c7-ea393359f5ba",
   "metadata": {},
   "source": [
    "########### PRE-PROCESSING THE STRING DATASET ##############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c6082617-87d0-4f77-90a7-24080f341cbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['May-15', 'Current', '36 months', ..., 'Verified',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=48010226', 'CA'],\n",
       "       ['', 'Current', '36 months', ..., 'Source Verified',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=57693261', 'NY'],\n",
       "       ['Sep-15', 'Current', '36 months', ..., 'Verified',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=59432726', 'PA'],\n",
       "       ...,\n",
       "       ['Jun-15', 'Current', '36 months', ..., 'Source Verified',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=50415990', 'CA'],\n",
       "       ['Apr-15', 'Current', '36 months', ..., 'Source Verified',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=46154151', 'OH'],\n",
       "       ['Dec-15', 'Current', '36 months', ..., '',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=66055249', 'IL']],\n",
       "      dtype='<U69')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating checkpoints - avoid losing progress, it's more like a failsafe\n",
    "def checkpoint(file_name, checkpoint_header, checkpoint_data):\n",
    "    np.savez(file_name, header = checkpoint_header, data = checkpoint_data)\n",
    "    checkpoint_variable = np.load(file_name + \".npz\")\n",
    "    return(checkpoint_variable)\n",
    "checkpoint_test = checkpoint(\"checkpoint-test\", header_string, loan_data_strings)\n",
    "checkpoint_test['data']\n",
    "checkpoint_test['header']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a5fbbe72-90c5-466c-b8fb-715443de2c73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['issue_date', 'loan_status', 'term', 'grade', 'sub_grade', 'verification_status', 'url',\n",
       "       'addr_state'], dtype='<U19')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header_string[0] = \"issue_date\"\n",
    "header_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9459a382-f1aa-454b-8f65-6631edc070f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', 'Apr-15', 'Aug-15', 'Dec-15', 'Feb-15', 'Jan-15', 'Jul-15', 'Jun-15', 'Mar-15',\n",
       "       'May-15', 'Nov-15', 'Oct-15', 'Sep-15'], dtype='<U69')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(loan_data_strings[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c3b64317-d447-4f80-b7a0-f0cf72eb6862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "chararray(['May', '', 'Sep', ..., 'Jun', 'Apr', 'Dec'], dtype='<U69')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.chararray.strip(loan_data_strings[:,0],\"-15\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cf8c5a-37c9-4ed6-8b61-e5630b8da98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(13):\n",
    "    loan_data_strings[:,0] = np.where(loan_data_strings[:,0] == months[i],\n",
    "                                      i,loan_data_strings[:,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "beac76ef-bc9f-4e09-8223-6367679de928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', 'Apr-15', 'Aug-15', 'Dec-15', 'Feb-15', 'Jan-15', 'Jul-15', 'Jun-15', 'Mar-15',\n",
       "       'May-15', 'Nov-15', 'Oct-15', 'Sep-15'], dtype='<U69')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(loan_data_strings[:,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7bc947ae-3474-4011-8edd-1af3b68d5b25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['issue_date', 'loan_status', 'term', 'grade', 'sub_grade', 'verification_status', 'url',\n",
       "       'addr_state'], dtype='<U19')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5ee57300-c0d9-4545-8c41-4e255f15ae02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', 'Charged Off', 'Current', 'Default', 'Fully Paid', 'In Grace Period', 'Issued',\n",
       "       'Late (16-30 days)', 'Late (31-120 days)'], dtype='<U69')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loan status\n",
    "np.unique(loan_data_strings[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "df094b15-6508-4720-b399-28997c252510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(loan_data_strings[:,1]).size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4c9571f0-bd30-484d-96e4-e321b9b5719e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', '36 months', '60 months'], dtype='<U69')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "status_bad = np.array(['', 'Charged Off', 'Default', 'Late (31-120 days)'])\n",
    "loan_data_strings[:,1] = np.where(np.isin(loan_data_strings[:,1],status_bad),0,1)\n",
    "np.unique(loan_data_strings[:,2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "cb21feba-c43d-404d-957c-930ab265b482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['36 ', '60', '60 '], dtype='<U69')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loan_data_strings[:,2] = np.chararray.strip(loan_data_strings[:,2],\"months\")\n",
    "loan_data_strings[:,2]\n",
    "header_string[2] = \"term_months\"\n",
    "loan_data_strings[:,2] = np.where(loan_data_strings[:,2] == '','60',loan_data_strings[:,2])\n",
    "loan_data_strings[:,2]\n",
    "np.unique(loan_data_strings[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5b6c4c8f-94e6-42f8-9a6a-d6d4e6adbd4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['C', 'A', 'B', ..., 'A', 'D', 'A'], dtype='<U69')"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loan_data_strings[:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f8fc1181-1504-46d4-aa18-356ffe9a7b8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', 'A', 'B', 'C', 'D', 'E', 'F', 'G'], dtype='<U69')"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(loan_data_strings[:,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e03b084c-3c85-461a-986a-d17ce757397c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', 'A1', 'A2', 'A3', 'A4', 'A5', 'B1', 'B2', 'B3', 'B4', 'B5', 'C1', 'C2', 'C3', 'C4',\n",
       "       'C5', 'D1', 'D2', 'D3', 'D4', 'D5', 'E1', 'E2', 'E3', 'E4', 'E5', 'F1', 'F2', 'F3', 'F4',\n",
       "       'F5', 'G1', 'G2', 'G3', 'G4', 'G5'], dtype='<U69')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(loan_data_strings[:,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "488baff3-9ce8-4e2d-a587-10c3adb07ab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['issue_date', 'loan_status', 'term_months', 'grade', 'sub_grade', 'verification_status',\n",
       "       'url', 'addr_state'], dtype='<U19')"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verification status\n",
    "header_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "623a8616-c7b5-432c-8754-5aaaed6eb0ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', 'Not Verified', 'Source Verified', 'Verified'], dtype='<U69')"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(loan_data_strings[:,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "fc16c8a3-492e-4a84-b75f-60d31261c627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['', 'AK', 'AL', 'AR', 'AZ', 'CA', 'CO', 'CT', 'DC', 'DE', 'FL', 'GA', 'HI', 'IL', 'IN',\n",
       "        'KS', 'KY', 'LA', 'MA', 'MD', 'ME', 'MI', 'MN', 'MO', 'MS', 'MT', 'NC', 'ND', 'NE', 'NH',\n",
       "        'NJ', 'NM', 'NV', 'NY', 'OH', 'OK', 'OR', 'PA', 'RI', 'SC', 'SD', 'TN', 'TX', 'UT', 'VA',\n",
       "        'VT', 'WA', 'WI', 'WV', 'WY'], dtype='<U69'),\n",
       " array([ 500,   26,  119,   74,  220, 1336,  201,  143,   27,   27,  690,  321,   44,  389,  152,\n",
       "          84,   84,  116,  210,  222,   10,  267,  156,  160,   61,   28,  261,   16,   25,   58,\n",
       "         341,   57,  130,  777,  312,   83,  108,  320,   40,  107,   24,  143,  758,   74,  242,\n",
       "          17,  216,  148,   49,   27], dtype=int64))"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(loan_data_strings[:,7], return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7ecf06-b9fa-4a6c-ab54-2ce650bf31d7",
   "metadata": {},
   "source": [
    "############# ABSENTEEISM DATA CLEANING ##############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48c582e0-a182-41d3-b4d7-52be3b533100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "5f9882f0-8ee7-4757-b312-40ee274e25aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(701, 12)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading data using numpy\n",
    "abs_np = np.genfromtxt(\"C:\\\\Users\\\\TJO1COB\\\\DataAnalytics\\\\Absenteeism-data.csv\", delimiter= ',' , autostrip= True)\n",
    "# np.set_printoptions(suppress=True, linewidth=100, precision=2)\n",
    "abs_np\n",
    "abs_np.shape #in numpy the shape is calculated by consdering the header as well, while that's not the case in pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a243b24-bf37-4cbf-adcb-b18fa9a0f5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data using pandas - eyeball your data first\n",
    "abs_pd = pd.read_csv(\"C:\\\\Users\\\\TJO1COB\\\\DataAnalytics\\\\Absenteeism-data.csv\" , delimiter= ',' )\n",
    "abs_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "b0f84cc3-151c-4796-90d7-feea2ded850f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Reason for Absence</th>\n",
       "      <th>Date</th>\n",
       "      <th>Transportation Expense</th>\n",
       "      <th>Distance to Work</th>\n",
       "      <th>Age</th>\n",
       "      <th>Daily Work Load Average</th>\n",
       "      <th>Body Mass Index</th>\n",
       "      <th>Education</th>\n",
       "      <th>Children</th>\n",
       "      <th>Pets</th>\n",
       "      <th>Absenteeism Time in Hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>26</td>\n",
       "      <td>07/07/2015</td>\n",
       "      <td>289</td>\n",
       "      <td>36</td>\n",
       "      <td>33</td>\n",
       "      <td>239.554</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>14/07/2015</td>\n",
       "      <td>118</td>\n",
       "      <td>13</td>\n",
       "      <td>50</td>\n",
       "      <td>239.554</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>15/07/2015</td>\n",
       "      <td>179</td>\n",
       "      <td>51</td>\n",
       "      <td>38</td>\n",
       "      <td>239.554</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>16/07/2015</td>\n",
       "      <td>279</td>\n",
       "      <td>5</td>\n",
       "      <td>39</td>\n",
       "      <td>239.554</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>23/07/2015</td>\n",
       "      <td>289</td>\n",
       "      <td>36</td>\n",
       "      <td>33</td>\n",
       "      <td>239.554</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Reason for Absence        Date  Transportation Expense  \\\n",
       "0  11                  26  07/07/2015                     289   \n",
       "1  36                   0  14/07/2015                     118   \n",
       "2   3                  23  15/07/2015                     179   \n",
       "3   7                   7  16/07/2015                     279   \n",
       "4  11                  23  23/07/2015                     289   \n",
       "\n",
       "   Distance to Work  Age  Daily Work Load Average  Body Mass Index  Education  \\\n",
       "0                36   33                  239.554               30          1   \n",
       "1                13   50                  239.554               31          1   \n",
       "2                51   38                  239.554               31          1   \n",
       "3                 5   39                  239.554               24          1   \n",
       "4                36   33                  239.554               30          1   \n",
       "\n",
       "   Children  Pets  Absenteeism Time in Hours  \n",
       "0         2     1                          4  \n",
       "1         1     0                          0  \n",
       "2         0     0                          2  \n",
       "3         2     0                          4  \n",
       "4         2     1                          2  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a copy of inital dataset\n",
    "df = abs_pd.copy()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5f659c-d3f0-4881-aa42-6481333abe2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.size\n",
    "df.shape\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5562d47a-13a3-4e3f-966a-eabfd958bb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  to display the complete dataset in jupyter use max method - to observe the entire dataset :\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "0906690e-42b1-4567-acfd-b963b3be43e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 700 entries, 0 to 699\n",
      "Data columns (total 12 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   ID                         700 non-null    int64  \n",
      " 1   Reason for Absence         700 non-null    int64  \n",
      " 2   Date                       700 non-null    object \n",
      " 3   Transportation Expense     700 non-null    int64  \n",
      " 4   Distance to Work           700 non-null    int64  \n",
      " 5   Age                        700 non-null    int64  \n",
      " 6   Daily Work Load Average    700 non-null    float64\n",
      " 7   Body Mass Index            700 non-null    int64  \n",
      " 8   Education                  700 non-null    int64  \n",
      " 9   Children                   700 non-null    int64  \n",
      " 10  Pets                       700 non-null    int64  \n",
      " 11  Absenteeism Time in Hours  700 non-null    int64  \n",
      "dtypes: float64(1), int64(10), object(1)\n",
      "memory usage: 65.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# info () prints a concise summary of the dataframe\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4014213-f6e9-4625-a759-20729c3ef1e3",
   "metadata": {},
   "source": [
    "################# variable can also be referred as feature, input, attribute ###############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "5161c2c9-3eb3-4e33-ae39-929e4a73d78d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reason for Absence</th>\n",
       "      <th>Date</th>\n",
       "      <th>Transportation Expense</th>\n",
       "      <th>Distance to Work</th>\n",
       "      <th>Age</th>\n",
       "      <th>Daily Work Load Average</th>\n",
       "      <th>Body Mass Index</th>\n",
       "      <th>Education</th>\n",
       "      <th>Children</th>\n",
       "      <th>Pets</th>\n",
       "      <th>Absenteeism Time in Hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26</td>\n",
       "      <td>07/07/2015</td>\n",
       "      <td>289</td>\n",
       "      <td>36</td>\n",
       "      <td>33</td>\n",
       "      <td>239.554</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>14/07/2015</td>\n",
       "      <td>118</td>\n",
       "      <td>13</td>\n",
       "      <td>50</td>\n",
       "      <td>239.554</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23</td>\n",
       "      <td>15/07/2015</td>\n",
       "      <td>179</td>\n",
       "      <td>51</td>\n",
       "      <td>38</td>\n",
       "      <td>239.554</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>16/07/2015</td>\n",
       "      <td>279</td>\n",
       "      <td>5</td>\n",
       "      <td>39</td>\n",
       "      <td>239.554</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23</td>\n",
       "      <td>23/07/2015</td>\n",
       "      <td>289</td>\n",
       "      <td>36</td>\n",
       "      <td>33</td>\n",
       "      <td>239.554</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Reason for Absence        Date  Transportation Expense  Distance to Work  \\\n",
       "0                  26  07/07/2015                     289                36   \n",
       "1                   0  14/07/2015                     118                13   \n",
       "2                  23  15/07/2015                     179                51   \n",
       "3                   7  16/07/2015                     279                 5   \n",
       "4                  23  23/07/2015                     289                36   \n",
       "\n",
       "   Age  Daily Work Load Average  Body Mass Index  Education  Children  Pets  \\\n",
       "0   33                  239.554               30          1         2     1   \n",
       "1   50                  239.554               31          1         1     0   \n",
       "2   38                  239.554               31          1         0     0   \n",
       "3   39                  239.554               24          1         2     0   \n",
       "4   33                  239.554               30          1         2     1   \n",
       "\n",
       "   Absenteeism Time in Hours  \n",
       "0                          4  \n",
       "1                          0  \n",
       "2                          2  \n",
       "3                          4  \n",
       "4                          2  "
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TASK - predict absenteeism form work - using statistical approach to solve this; for this absenteeism value is the dependent variable\n",
    "# drop ID variable\n",
    "df = df.drop(['ID'], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "b3fe8343-1e3c-4aec-ba74-76b097672ed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# analysis of reason for absence\n",
    "df['Reason for Absence'].max()\n",
    "df['Reason for Absence'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "9b937ede-b705-4516-bb08-009e742eefcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([26,  0, 23,  7, 22, 19,  1, 11, 14, 21, 10, 13, 28, 18, 25, 24,  6, 27, 17,  8, 12,  5,  9,\n",
       "       15,  4,  3,  2, 16], dtype=int64)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extracting a list containing distinct values only\n",
    "pd.unique(df['Reason for Absence']) #or :\n",
    "df['Reason for Absence'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "b466576c-160e-4422-a7bd-383557991b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# obtain how many different reasons for absent in work \n",
    "len(df['Reason for Absence'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "9713e4bb-a5dd-4f0a-a86a-eb6c84f04754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(df['Reason for Absence'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "cc19d29c-123b-468a-bd8f-cbf3fac863b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1   2   3   4   5   6   7   8   9   10  11  12  13  14  15  16  17  18  \\\n",
       "0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "1   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "3   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   \n",
       "4   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "\n",
       "   19  21  22  23  24  25  26  27  28  \n",
       "0   0   0   0   0   0   0   1   0   0  \n",
       "1   0   0   0   0   0   0   0   0   0  \n",
       "2   0   0   0   1   0   0   0   0   0  \n",
       "3   0   0   0   0   0   0   0   0   0  \n",
       "4   0   0   0   1   0   0   0   0   0  "
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# splitting the reasons for absence into multiple dummy variables with 1(for reason present) and 0(for reason absent)\n",
    "reason_cols = pd.get_dummies(df['Reason for Absence'])\n",
    "reason_cols.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a2d5f7-aa82-45c8-adc3-6f4e3a509974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a check col \n",
    "reason_cols['check'] = reason_cols.sum(axis = 1)\n",
    "reason_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "ca47a000-a500-4d3a-b166-4e29fa18fbc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reason_cols['check'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "aaaa47c5-831f-4c09-a33d-b62400b4b2d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   1   2   3   4   5   6   7   8   9   10  11  12  13  14  15  16  17  18  19  \\\n",
       "0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "3   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "4   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "\n",
       "   21  22  23  24  25  26  27  28  \n",
       "0   0   0   0   0   0   1   0   0  \n",
       "1   0   0   0   0   0   0   0   0  \n",
       "2   0   0   1   0   0   0   0   0  \n",
       "3   0   0   0   0   0   0   0   0  \n",
       "4   0   0   1   0   0   0   0   0  "
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dropping reason 0 from the dataset\n",
    "reason_cols = pd.get_dummies(df['Reason for Absence'], drop_first=True)\n",
    "reason_cols.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "360e5332-d4c4-46c5-a6dc-74a3c38dde2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Reason for Absence', 'Date', 'Transportation Expense', 'Distance to Work', 'Age',\n",
       "       'Daily Work Load Average', 'Body Mass Index', 'Education', 'Children', 'Pets',\n",
       "       'Absenteeism Time in Hours'], dtype=object)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "8b6f8584-1f13-41d3-bd60-199ee8f70ea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24,\n",
       "       25, 26, 27, 28], dtype=int64)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reason_cols.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8bebe2-6d91-403c-971d-bb5ed1f52dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.drop(df['Reason for Absence'])\n",
    "df = df.drop(['Reason for Absence'], axis = 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "51ca9060-2740-4dec-882d-ebc39445d3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouping the reason cols\n",
    "reason_type1 = reason_cols.loc[:,'1':'14'].max(axis = 1)\n",
    "reason_type2 = reason_cols.loc[:,15:17].max(axis = 1)\n",
    "reason_type3 = reason_cols.loc[:,18:21].max(axis=1)\n",
    "reason_type4 = reason_cols.loc[:,22:].max(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "5f0bd14e-43e7-47cc-ac94-c80c86a943c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    0\n",
       "2    1\n",
       "3    0\n",
       "4    1\n",
       "dtype: uint8"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reason_type4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bdb3e0-cdf7-4646-95b1-c82edcc4e9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate col values\n",
    "df = pd.concat([df, reason_type1, reason_type2, reason_type3, reason_type4], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "9f5853c4-b3fc-48d4-9e44-bdad10d53bb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Date', 'Transportation Expense', 'Distance to Work', 'Age', 'Daily Work Load Average',\n",
       "       'Body Mass Index', 'Education', 'Children', 'Pets', 'Absenteeism Time in Hours', 0, 1, 2, 3,\n",
       "       0, 1, 2, 3], dtype=object)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ee6c7d-20b2-4010-a01d-3d63d9a8d4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = ['Date', 'Transportation Expense', 'Distance to Work', 'Age', 'Daily Work Load Average',\n",
    "       'Body Mass Index', 'Education', 'Children', 'Pets', 'Absenteeism Time in Hours', 'reason_type1', 'reason_type2', 'reason_type3', 'reason_type4']\n",
    "df.columns = col_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70341012-0fed-464e-8cd8-127ba045cc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9957c6c6-3abe-4bb0-876f-e35828971bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorder cols \n",
    "reorder_cols = ['reason_type1', 'reason_type2', 'reason_type3', 'reason_type4','Date', 'Transportation Expense', 'Distance to Work', 'Age', 'Daily Work Load Average',\n",
    "       'Body Mass Index', 'Education', 'Children', 'Pets', 'Absenteeism Time in Hours']\n",
    "df = df[reorder_cols]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "439ff3b1-1bdf-4f4d-bcd3-e760b5884943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create checkpoints - To create a checkpoint of your work, you can store the current output (df_concatenated, for example) in a variable called df_checkpoint. \n",
    "df_mod = df.copy()\n",
    "df_mod\n",
    "# df_checkpoint = df_concatenated.copy()\n",
    "# df_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9da3bc-9096-48d9-ae37-1d9447977fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspecting date column of the dataframe\n",
    "df['Date']\n",
    "type(df['Date'][0])\n",
    "# introducing time_stamp variable which is common data type in programming languages, used for values representing date and time. to convert all values from data col to timestamp val, use pandas to datetime method\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df['Date'] = pd.to_datetime(df['Date'], format = '%d/%m/%Y')\n",
    "df]['Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29045839-6faa-47e9-b511-257fee99531e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting month\n",
    "df['Date'][0].month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378d354e-99b8-4132-8e26-95dfe17eba38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a column designated for day of week. weekday module starts from 0 to 6\n",
    "df_mod['Date'][699].weekday()\n",
    "def date_to_weekday(date_val):\n",
    "    return date_val.weekday()\n",
    "df_mod['day of week'] = df_mod['Date'].apply(date_to_weekday)\n",
    "df_mod.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c96d1d-ac02-4c1d-8f40-08ac6f5de393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfer the education col to a dummy variable using the map function\n",
    "df['Education'].unique()\n",
    "# using the vals_counts () that retrievs sum of unique values present\n",
    "df['Education'].value_counts()\n",
    "df['Education'] = df['Education'].map({1:0, 2:1, 3:1, 4:1})\n",
    "df['Education'].unique()\n",
    "df['Education'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ea9a8c-6f4a-4faa-b623-2c4cf920734d",
   "metadata": {},
   "source": [
    "2 TYPES OF DATA :\n",
    " 1. CATEGORICAL - describes groups eg, AUDI, BMW); YES AND NO QUESTIONS\n",
    " 2. NUMERICAL DATA SUGGESTS NUMBERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed23f20-c903-4ea4-86c0-ee74ba826d1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "5f299e8b-9a73-481a-bf39-bc54cbd7960d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917b5b09-dcf5-43c0-a79f-a47d5a9f3854",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
